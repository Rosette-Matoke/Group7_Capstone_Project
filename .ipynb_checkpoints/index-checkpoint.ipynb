{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3a13801-58a2-4e19-b13f-bc28cd0488ef",
   "metadata": {
    "id": "a3a13801-58a2-4e19-b13f-bc28cd0488ef"
   },
   "source": [
    "# DAKTARI- THE AI MEDICAL CHATBOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcae89a-931f-4799-a25a-c04c0ae95640",
   "metadata": {
    "id": "cdcae89a-931f-4799-a25a-c04c0ae95640"
   },
   "source": [
    "# PROJECT SUMMARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e7485d-48cb-4955-87fb-552f56e91e2f",
   "metadata": {
    "id": "64e7485d-48cb-4955-87fb-552f56e91e2f"
   },
   "source": [
    "# 1. BUSINESS UNDERSTANDING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f702a413-97f5-4b72-93a6-65103c750b3d",
   "metadata": {
    "id": "f702a413-97f5-4b72-93a6-65103c750b3d"
   },
   "source": [
    "# 2. BUSINESS PROBLEM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1626f89b-4590-4bae-a63e-8133c52f3b94",
   "metadata": {
    "id": "1626f89b-4590-4bae-a63e-8133c52f3b94"
   },
   "source": [
    "# 3. OBJECTIVES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a5bc1c-49db-4d3a-80ee-d40ee7580bcf",
   "metadata": {
    "id": "20a5bc1c-49db-4d3a-80ee-d40ee7580bcf"
   },
   "source": [
    "## 3.1 Main objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc9ca01-2799-4196-9026-b4ab29aa99d9",
   "metadata": {
    "id": "2fc9ca01-2799-4196-9026-b4ab29aa99d9"
   },
   "source": [
    "## 3.2 Specific objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e5bbbd-efa9-40e6-906a-0f2433a76d87",
   "metadata": {
    "id": "d9e5bbbd-efa9-40e6-906a-0f2433a76d87"
   },
   "source": [
    "## 3.3 Research Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caec4643-06a9-4c1f-99b9-71750c6d3dad",
   "metadata": {
    "id": "caec4643-06a9-4c1f-99b9-71750c6d3dad"
   },
   "source": [
    "## 3.4 Metric of success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4143d22c-6b0e-44b3-a9fe-6e2d6495fefd",
   "metadata": {
    "id": "4143d22c-6b0e-44b3-a9fe-6e2d6495fefd"
   },
   "source": [
    "# 4. DATA UNDERSTANDING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4950e8d-8103-4dab-ab08-8fce263a6208",
   "metadata": {
    "id": "f4950e8d-8103-4dab-ab08-8fce263a6208"
   },
   "source": [
    "## 4.1 Data Limitation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f1574e-6de8-4f95-987f-a93bbc79b7d9",
   "metadata": {
    "id": "e8f1574e-6de8-4f95-987f-a93bbc79b7d9"
   },
   "source": [
    "# 5. DATA EXPLORATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c857b6-60e7-4aad-8dd4-5f25b29403a6",
   "metadata": {
    "id": "e8c857b6-60e7-4aad-8dd4-5f25b29403a6"
   },
   "source": [
    "## 5.1 Loading a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbe9421d-6ce8-4af4-ab83-d6e87d8822bb",
   "metadata": {
    "id": "bbe9421d-6ce8-4af4-ab83-d6e87d8822bb"
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b285469-1be8-411e-b00f-042ecd720406",
   "metadata": {
    "id": "6b285469-1be8-411e-b00f-042ecd720406"
   },
   "outputs": [],
   "source": [
    "# pip install huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ade30278-8cf9-4e36-aac6-5786c6e594de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ade30278-8cf9-4e36-aac6-5786c6e594de",
    "outputId": "2d39bf3f-0a8f-4452-dd6d-6a0b6ea7131f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Patient</th>\n",
       "      <th>Doctor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q. What does abutment of the nerve root mean?</td>\n",
       "      <td>Hi doctor,I am just wondering what is abutting...</td>\n",
       "      <td>Hi. I have gone through your query with dilige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q. What should I do to reduce my weight gained...</td>\n",
       "      <td>Hi doctor, I am a 22-year-old female who was d...</td>\n",
       "      <td>Hi. You have really done well with the hypothy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q. I have started to get lots of acne on my fa...</td>\n",
       "      <td>Hi doctor! I used to have clear skin but since...</td>\n",
       "      <td>Hi there Acne has multifactorial etiology. Onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q. Why do I have uncomfortable feeling between...</td>\n",
       "      <td>Hello doctor,I am having an uncomfortable feel...</td>\n",
       "      <td>Hello. The popping and discomfort what you fel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q. My symptoms after intercourse threatns me e...</td>\n",
       "      <td>Hello doctor,Before two years had sex with a c...</td>\n",
       "      <td>Hello. The HIV test uses a finger prick blood ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description  \\\n",
       "0      Q. What does abutment of the nerve root mean?   \n",
       "1  Q. What should I do to reduce my weight gained...   \n",
       "2  Q. I have started to get lots of acne on my fa...   \n",
       "3  Q. Why do I have uncomfortable feeling between...   \n",
       "4  Q. My symptoms after intercourse threatns me e...   \n",
       "\n",
       "                                             Patient  \\\n",
       "0  Hi doctor,I am just wondering what is abutting...   \n",
       "1  Hi doctor, I am a 22-year-old female who was d...   \n",
       "2  Hi doctor! I used to have clear skin but since...   \n",
       "3  Hello doctor,I am having an uncomfortable feel...   \n",
       "4  Hello doctor,Before two years had sex with a c...   \n",
       "\n",
       "                                              Doctor  \n",
       "0  Hi. I have gone through your query with dilige...  \n",
       "1  Hi. You have really done well with the hypothy...  \n",
       "2  Hi there Acne has multifactorial etiology. Onl...  \n",
       "3  Hello. The popping and discomfort what you fel...  \n",
       "4  Hello. The HIV test uses a finger prick blood ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"hf://datasets/DrBenjamin/ai-medical-chatbot/dialogues.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bead0f63-e1a9-4802-af46-157ab49df77e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bead0f63-e1a9-4802-af46-157ab49df77e",
    "outputId": "21f414dc-f3a2-4802-f552-9406f2858aba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256916, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c6370c9-721e-419a-8dde-09aad81ee379",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1c6370c9-721e-419a-8dde-09aad81ee379",
    "outputId": "322307ee-df06-4b30-f2b6-c3c314c2971a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 256916 entries, 0 to 256915\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   Description  256916 non-null  object\n",
      " 1   Patient      256916 non-null  object\n",
      " 2   Doctor       256916 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc85deae-6f16-4b0f-8159-eb2e1201138a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "bc85deae-6f16-4b0f-8159-eb2e1201138a",
    "outputId": "e793f6ec-55be-4c29-f2a4-76482e9a8655"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Description    0\n",
       "Patient        0\n",
       "Doctor         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105154fb-6afe-4744-b883-60ea0779603b",
   "metadata": {
    "id": "105154fb-6afe-4744-b883-60ea0779603b"
   },
   "source": [
    "Since our data is not missing any missing values we can move to cleaning the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82dbf8d-c837-46e1-9c3a-18a2984e349e",
   "metadata": {
    "id": "f82dbf8d-c837-46e1-9c3a-18a2984e349e"
   },
   "source": [
    "## 5.2 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f72e8e9d-99e3-4f25-8442-845e84d1b79d",
   "metadata": {
    "id": "f72e8e9d-99e3-4f25-8442-845e84d1b79d"
   },
   "outputs": [],
   "source": [
    "import nltk # natural language toolkit\n",
    "import re # regular expressions\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import FreqDist\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad4f1c85-5d9c-4f52-b4f8-88b07c8f713b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ad4f1c85-5d9c-4f52-b4f8-88b07c8f713b",
    "outputId": "af95897f-6c3f-4f68-bb98-884965159f7a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Halla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Halla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Halla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Halla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae875b5-53f1-45ce-b5f9-f20bab148201",
   "metadata": {
    "id": "9ae875b5-53f1-45ce-b5f9-f20bab148201"
   },
   "source": [
    "### 5.2.1 Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7521dba3-6eaf-4b60-a54c-6aa8f3fbd166",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7521dba3-6eaf-4b60-a54c-6aa8f3fbd166",
    "outputId": "fb889870-b46c-40a0-e6a5-588d05b7cbaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Description', 'Patient', 'Doctor'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7758501-1e4c-4733-9861-1c5a6840eef3",
   "metadata": {
    "id": "d7758501-1e4c-4733-9861-1c5a6840eef3"
   },
   "source": [
    "**Tokenization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99baa13e-7d22-4b70-af1d-777ad8722b55",
   "metadata": {
    "id": "99baa13e-7d22-4b70-af1d-777ad8722b55"
   },
   "source": [
    "Let's breaks down each text into a list of words **tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "937a2e5a-85f8-4839-99ce-60cf5e1615fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "937a2e5a-85f8-4839-99ce-60cf5e1615fa",
    "outputId": "d0378cad-2917-4439-ce2c-fe03eb6183f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Halla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Halla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description_cleaned</th>\n",
       "      <th>Patient_cleaned</th>\n",
       "      <th>Doctor_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Q, ., What, does, abutment, of, the, nerve, r...</td>\n",
       "      <td>[Hi, doctor, ,, I, am, just, wondering, what, ...</td>\n",
       "      <td>[Hi, ., I, have, gone, through, your, query, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Q, ., What, should, I, do, to, reduce, my, we...</td>\n",
       "      <td>[Hi, doctor, ,, I, am, a, 22-year-old, female,...</td>\n",
       "      <td>[Hi, ., You, have, really, done, well, with, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Q., I, have, started, to, get, lots, of, acne...</td>\n",
       "      <td>[Hi, doctor, !, I, used, to, have, clear, skin...</td>\n",
       "      <td>[Hi, there, Acne, has, multifactorial, etiolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Q, ., Why, do, I, have, uncomfortable, feelin...</td>\n",
       "      <td>[Hello, doctor, ,, I, am, having, an, uncomfor...</td>\n",
       "      <td>[Hello, ., The, popping, and, discomfort, what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Q, ., My, symptoms, after, intercourse, threa...</td>\n",
       "      <td>[Hello, doctor, ,, Before, two, years, had, se...</td>\n",
       "      <td>[Hello, ., The, HIV, test, uses, a, finger, pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Description_cleaned  \\\n",
       "0  [Q, ., What, does, abutment, of, the, nerve, r...   \n",
       "1  [Q, ., What, should, I, do, to, reduce, my, we...   \n",
       "2  [Q., I, have, started, to, get, lots, of, acne...   \n",
       "3  [Q, ., Why, do, I, have, uncomfortable, feelin...   \n",
       "4  [Q, ., My, symptoms, after, intercourse, threa...   \n",
       "\n",
       "                                     Patient_cleaned  \\\n",
       "0  [Hi, doctor, ,, I, am, just, wondering, what, ...   \n",
       "1  [Hi, doctor, ,, I, am, a, 22-year-old, female,...   \n",
       "2  [Hi, doctor, !, I, used, to, have, clear, skin...   \n",
       "3  [Hello, doctor, ,, I, am, having, an, uncomfor...   \n",
       "4  [Hello, doctor, ,, Before, two, years, had, se...   \n",
       "\n",
       "                                      Doctor_cleaned  \n",
       "0  [Hi, ., I, have, gone, through, your, query, w...  \n",
       "1  [Hi, ., You, have, really, done, well, with, t...  \n",
       "2  [Hi, there, Acne, has, multifactorial, etiolog...  \n",
       "3  [Hello, ., The, popping, and, discomfort, what...  \n",
       "4  [Hello, ., The, HIV, test, uses, a, finger, pr...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply tokenization to each text column\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "for col in ['Description', 'Patient', 'Doctor']:\n",
    "    df[col + '_cleaned'] = df[col].astype(str).apply(word_tokenize)\n",
    "\n",
    "df[['Description_cleaned', 'Patient_cleaned', 'Doctor_cleaned']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d5c55d-c354-4d94-85a3-2fb7c1492f8b",
   "metadata": {
    "id": "b0d5c55d-c354-4d94-85a3-2fb7c1492f8b"
   },
   "source": [
    "**Lowercasing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ba2516-787c-484c-96a3-b54623ed0f96",
   "metadata": {
    "id": "e0ba2516-787c-484c-96a3-b54623ed0f96"
   },
   "source": [
    "Let's convert our tokenized text to **lowercase** to ensure consistency in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d2c9719-309d-4e31-ad6d-fedaad528518",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "3d2c9719-309d-4e31-ad6d-fedaad528518",
    "outputId": "3f419d24-5094-4da6-9d4a-d4ab2b73c553"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description_cleaned</th>\n",
       "      <th>Patient_cleaned</th>\n",
       "      <th>Doctor_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[q, ., what, does, abutment, of, the, nerve, r...</td>\n",
       "      <td>[hi, doctor, ,, i, am, just, wondering, what, ...</td>\n",
       "      <td>[hi, ., i, have, gone, through, your, query, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[q, ., what, should, i, do, to, reduce, my, we...</td>\n",
       "      <td>[hi, doctor, ,, i, am, a, 22-year-old, female,...</td>\n",
       "      <td>[hi, ., you, have, really, done, well, with, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[q., i, have, started, to, get, lots, of, acne...</td>\n",
       "      <td>[hi, doctor, !, i, used, to, have, clear, skin...</td>\n",
       "      <td>[hi, there, acne, has, multifactorial, etiolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[q, ., why, do, i, have, uncomfortable, feelin...</td>\n",
       "      <td>[hello, doctor, ,, i, am, having, an, uncomfor...</td>\n",
       "      <td>[hello, ., the, popping, and, discomfort, what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[q, ., my, symptoms, after, intercourse, threa...</td>\n",
       "      <td>[hello, doctor, ,, before, two, years, had, se...</td>\n",
       "      <td>[hello, ., the, hiv, test, uses, a, finger, pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Description_cleaned  \\\n",
       "0  [q, ., what, does, abutment, of, the, nerve, r...   \n",
       "1  [q, ., what, should, i, do, to, reduce, my, we...   \n",
       "2  [q., i, have, started, to, get, lots, of, acne...   \n",
       "3  [q, ., why, do, i, have, uncomfortable, feelin...   \n",
       "4  [q, ., my, symptoms, after, intercourse, threa...   \n",
       "\n",
       "                                     Patient_cleaned  \\\n",
       "0  [hi, doctor, ,, i, am, just, wondering, what, ...   \n",
       "1  [hi, doctor, ,, i, am, a, 22-year-old, female,...   \n",
       "2  [hi, doctor, !, i, used, to, have, clear, skin...   \n",
       "3  [hello, doctor, ,, i, am, having, an, uncomfor...   \n",
       "4  [hello, doctor, ,, before, two, years, had, se...   \n",
       "\n",
       "                                      Doctor_cleaned  \n",
       "0  [hi, ., i, have, gone, through, your, query, w...  \n",
       "1  [hi, ., you, have, really, done, well, with, t...  \n",
       "2  [hi, there, acne, has, multifactorial, etiolog...  \n",
       "3  [hello, ., the, popping, and, discomfort, what...  \n",
       "4  [hello, ., the, hiv, test, uses, a, finger, pr...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert all tokens to lowercase\n",
    "for col in ['Description_cleaned', 'Patient_cleaned', 'Doctor_cleaned']:\n",
    "    df[col] = df[col].apply(lambda x: [word.lower() for word in x])\n",
    "\n",
    "df[['Description_cleaned', 'Patient_cleaned', 'Doctor_cleaned']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b5905f-2065-45a0-99ad-ef6e2595a449",
   "metadata": {
    "id": "46b5905f-2065-45a0-99ad-ef6e2595a449"
   },
   "source": [
    "**Stopword Removal**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa30510-86a0-4a5b-b222-4d5f53c19733",
   "metadata": {
    "id": "9aa30510-86a0-4a5b-b222-4d5f53c19733"
   },
   "source": [
    "By removing **Stopwords** like *the, is, and*   which don’t really  carry meaningful information we reduce the noise in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ab9797b-6fc6-4736-b6a7-759a94ed6761",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "0ab9797b-6fc6-4736-b6a7-759a94ed6761",
    "outputId": "1274accb-6c32-482b-e53b-577cc3cc7509"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description_cleaned</th>\n",
       "      <th>Patient_cleaned</th>\n",
       "      <th>Doctor_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[., abutment, nerve, root, mean, ?]</td>\n",
       "      <td>[,, wondering, abutting, abutment, nerve, root...</td>\n",
       "      <td>[., gone, query, diligence, would, like, know,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[., reduce, weight, gained, due, genetic, hypo...</td>\n",
       "      <td>[,, 22-year-old, female, diagnosed, hypothyroi...</td>\n",
       "      <td>[., really, done, well, hypothyroidism, proble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[q., started, get, lots, acne, face, ,, partic...</td>\n",
       "      <td>[!, used, clear, skin, since, moved, new, plac...</td>\n",
       "      <td>[acne, multifactorial, etiology, ., acne, soap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[., uncomfortable, feeling, middle, spine, lef...</td>\n",
       "      <td>[,, uncomfortable, feeling, middle, spine, lef...</td>\n",
       "      <td>[., popping, discomfort, felt, either, imprope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[., symptoms, intercourse, threatns, even, neg...</td>\n",
       "      <td>[,, two, years, sex, call, girl, dark, locatio...</td>\n",
       "      <td>[., hiv, test, uses, finger, prick, blood, sam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Description_cleaned  \\\n",
       "0                [., abutment, nerve, root, mean, ?]   \n",
       "1  [., reduce, weight, gained, due, genetic, hypo...   \n",
       "2  [q., started, get, lots, acne, face, ,, partic...   \n",
       "3  [., uncomfortable, feeling, middle, spine, lef...   \n",
       "4  [., symptoms, intercourse, threatns, even, neg...   \n",
       "\n",
       "                                     Patient_cleaned  \\\n",
       "0  [,, wondering, abutting, abutment, nerve, root...   \n",
       "1  [,, 22-year-old, female, diagnosed, hypothyroi...   \n",
       "2  [!, used, clear, skin, since, moved, new, plac...   \n",
       "3  [,, uncomfortable, feeling, middle, spine, lef...   \n",
       "4  [,, two, years, sex, call, girl, dark, locatio...   \n",
       "\n",
       "                                      Doctor_cleaned  \n",
       "0  [., gone, query, diligence, would, like, know,...  \n",
       "1  [., really, done, well, hypothyroidism, proble...  \n",
       "2  [acne, multifactorial, etiology, ., acne, soap...  \n",
       "3  [., popping, discomfort, felt, either, imprope...  \n",
       "4  [., hiv, test, uses, finger, prick, blood, sam...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_remove = ['hi', 'hello', 'doctor', 'thanks', 'thank', 'please', 'kindly','q','but']\n",
    "stop_words = set(stopwords.words('english')+ words_to_remove)\n",
    "\n",
    "# Remove stopwords\n",
    "for col in ['Description_cleaned', 'Patient_cleaned', 'Doctor_cleaned']:\n",
    "    df[col] = df[col].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "df[['Description_cleaned', 'Patient_cleaned', 'Doctor_cleaned']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c94db7-f2eb-4528-b138-3c73ce23c2e2",
   "metadata": {
    "id": "38c94db7-f2eb-4528-b138-3c73ce23c2e2"
   },
   "source": [
    "**Punctuation Removal**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcab456-3150-45e3-a780-b1842bcc00c6",
   "metadata": {
    "id": "cfcab456-3150-45e3-a780-b1842bcc00c6"
   },
   "source": [
    "Removing punctuation marks like *!, ., ,*  because they rarely add semantic meaning in our text analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18c9686c-7b81-4fa9-a54e-70d61e252fb5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "18c9686c-7b81-4fa9-a54e-70d61e252fb5",
    "outputId": "35cade20-42db-4bc9-e780-f7ba9523a636"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description_cleaned</th>\n",
       "      <th>Patient_cleaned</th>\n",
       "      <th>Doctor_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[abutment, nerve, root, mean]</td>\n",
       "      <td>[wondering, abutting, abutment, nerve, root, m...</td>\n",
       "      <td>[gone, query, diligence, would, like, know, he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[reduce, weight, gained, due, genetic, hypothy...</td>\n",
       "      <td>[22-year-old, female, diagnosed, hypothyroidis...</td>\n",
       "      <td>[really, done, well, hypothyroidism, problem, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[q., started, get, lots, acne, face, particula...</td>\n",
       "      <td>[used, clear, skin, since, moved, new, place, ...</td>\n",
       "      <td>[acne, multifactorial, etiology, acne, soap, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[uncomfortable, feeling, middle, spine, left, ...</td>\n",
       "      <td>[uncomfortable, feeling, middle, spine, left, ...</td>\n",
       "      <td>[popping, discomfort, felt, either, improper, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[symptoms, intercourse, threatns, even, negati...</td>\n",
       "      <td>[two, years, sex, call, girl, dark, location, ...</td>\n",
       "      <td>[hiv, test, uses, finger, prick, blood, sample...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Description_cleaned  \\\n",
       "0                      [abutment, nerve, root, mean]   \n",
       "1  [reduce, weight, gained, due, genetic, hypothy...   \n",
       "2  [q., started, get, lots, acne, face, particula...   \n",
       "3  [uncomfortable, feeling, middle, spine, left, ...   \n",
       "4  [symptoms, intercourse, threatns, even, negati...   \n",
       "\n",
       "                                     Patient_cleaned  \\\n",
       "0  [wondering, abutting, abutment, nerve, root, m...   \n",
       "1  [22-year-old, female, diagnosed, hypothyroidis...   \n",
       "2  [used, clear, skin, since, moved, new, place, ...   \n",
       "3  [uncomfortable, feeling, middle, spine, left, ...   \n",
       "4  [two, years, sex, call, girl, dark, location, ...   \n",
       "\n",
       "                                      Doctor_cleaned  \n",
       "0  [gone, query, diligence, would, like, know, he...  \n",
       "1  [really, done, well, hypothyroidism, problem, ...  \n",
       "2  [acne, multifactorial, etiology, acne, soap, i...  \n",
       "3  [popping, discomfort, felt, either, improper, ...  \n",
       "4  [hiv, test, uses, finger, prick, blood, sample...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "for col in ['Description_cleaned', 'Patient_cleaned', 'Doctor_cleaned']:\n",
    "    df[col] = df[col].apply(lambda x: [word for word in x if word not in string.punctuation])\n",
    "\n",
    "df[['Description_cleaned', 'Patient_cleaned', 'Doctor_cleaned']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e80d47a-e610-47d8-a868-a296078e7bd1",
   "metadata": {
    "id": "1e80d47a-e610-47d8-a868-a296078e7bd1"
   },
   "source": [
    "**POS Tagging and Lemmatization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53215ce-b58f-4c28-8291-b62380a0c76a",
   "metadata": {
    "id": "d53215ce-b58f-4c28-8291-b62380a0c76a"
   },
   "source": [
    "**POS Tagging** involves labeling each word in a sentence with its grammatical part of speech such as nouns, adjectives, verbs and adjectives\n",
    "\n",
    "**Lemmatization** refines this using linguistic context better to good.\n",
    "Both this steps will help us unify variations of the same word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "89a6a82a-9dd3-42cc-8f51-fd4d05acdc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#POS tagging\n",
    "def get_pos(word):\n",
    "    tag = pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\n",
    "        'J': wordnet.ADJ,  # Represents an Adjective\n",
    "        'N': wordnet.NOUN, # Represents a Noun\n",
    "        'V': wordnet.VERB, # Represents a Verb\n",
    "        'R': wordnet.ADV   # Represents an Adverb\n",
    "    }\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "928d5209-ae26-47c9-9664-674ec21106d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Halla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Halla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "daef6e50-cabb-4c32-9a9b-5889a5e58ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description_cleaned</th>\n",
       "      <th>Patient_cleaned</th>\n",
       "      <th>Doctor_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[abutment, nerve, root, mean]</td>\n",
       "      <td>[wondering, abutting, abutment, nerve, root, m...</td>\n",
       "      <td>[gone, query, diligence, would, like, know, he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[reduce, weight, gained, due, genetic, hypothy...</td>\n",
       "      <td>[22-year-old, female, diagnosed, hypothyroidis...</td>\n",
       "      <td>[really, done, well, hypothyroidism, problem, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[q., started, get, lot, acne, face, particular...</td>\n",
       "      <td>[used, clear, skin, since, moved, new, place, ...</td>\n",
       "      <td>[acne, multifactorial, etiology, acne, soap, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[uncomfortable, feeling, middle, spine, left, ...</td>\n",
       "      <td>[uncomfortable, feeling, middle, spine, left, ...</td>\n",
       "      <td>[popping, discomfort, felt, either, improper, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[symptom, intercourse, threatns, even, negativ...</td>\n",
       "      <td>[two, year, sex, call, girl, dark, location, 1...</td>\n",
       "      <td>[hiv, test, us, finger, prick, blood, sample, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Description_cleaned  \\\n",
       "0                      [abutment, nerve, root, mean]   \n",
       "1  [reduce, weight, gained, due, genetic, hypothy...   \n",
       "2  [q., started, get, lot, acne, face, particular...   \n",
       "3  [uncomfortable, feeling, middle, spine, left, ...   \n",
       "4  [symptom, intercourse, threatns, even, negativ...   \n",
       "\n",
       "                                     Patient_cleaned  \\\n",
       "0  [wondering, abutting, abutment, nerve, root, m...   \n",
       "1  [22-year-old, female, diagnosed, hypothyroidis...   \n",
       "2  [used, clear, skin, since, moved, new, place, ...   \n",
       "3  [uncomfortable, feeling, middle, spine, left, ...   \n",
       "4  [two, year, sex, call, girl, dark, location, 1...   \n",
       "\n",
       "                                      Doctor_cleaned  \n",
       "0  [gone, query, diligence, would, like, know, he...  \n",
       "1  [really, done, well, hypothyroidism, problem, ...  \n",
       "2  [acne, multifactorial, etiology, acne, soap, i...  \n",
       "3  [popping, discomfort, felt, either, improper, ...  \n",
       "4  [hiv, test, us, finger, prick, blood, sample, ...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_tokens(tokens):\n",
    "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "# Apply to each column\n",
    "for col in ['Description_cleaned', 'Patient_cleaned', 'Doctor_cleaned']:\n",
    "    df[col] = df[col].apply(lemmatize_tokens)\n",
    "\n",
    "df[['Description_cleaned', 'Patient_cleaned', 'Doctor_cleaned']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9da3b3e8-f249-4be4-bbce-45962934e643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\halla\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.9.0-cp312-cp312-win_amd64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\halla\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\halla\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\halla\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\halla\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\halla\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\halla\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\halla\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\halla\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\halla\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\halla\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\halla\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\halla\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\halla\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\halla\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\halla\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\halla\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\halla\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\halla\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\halla\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\halla\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\halla\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\halla\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\halla\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\halla\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.10.5)\n",
      "Downloading sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n",
      "Downloading torch-2.9.0-cp312-cp312-win_amd64.whl (109.3 MB)\n",
      "   ---------------------------------------- 0.0/109.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/109.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/109.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/109.3 MB 1.1 MB/s eta 0:01:38\n",
      "   ---------------------------------------- 0.8/109.3 MB 1.1 MB/s eta 0:01:38\n",
      "   ---------------------------------------- 1.0/109.3 MB 1.0 MB/s eta 0:01:44\n",
      "   ---------------------------------------- 1.0/109.3 MB 1.0 MB/s eta 0:01:44\n",
      "   ---------------------------------------- 1.3/109.3 MB 1.0 MB/s eta 0:01:48\n",
      "    --------------------------------------- 1.6/109.3 MB 987.0 kB/s eta 0:01:50\n",
      "    --------------------------------------- 1.8/109.3 MB 967.9 kB/s eta 0:01:52\n",
      "    --------------------------------------- 1.8/109.3 MB 967.9 kB/s eta 0:01:52\n",
      "    --------------------------------------- 2.1/109.3 MB 987.1 kB/s eta 0:01:49\n",
      "    --------------------------------------- 2.4/109.3 MB 986.9 kB/s eta 0:01:49\n",
      "    --------------------------------------- 2.6/109.3 MB 980.6 kB/s eta 0:01:49\n",
      "   - -------------------------------------- 2.9/109.3 MB 981.1 kB/s eta 0:01:49\n",
      "   - -------------------------------------- 2.9/109.3 MB 981.1 kB/s eta 0:01:49\n",
      "   - -------------------------------------- 3.1/109.3 MB 956.1 kB/s eta 0:01:52\n",
      "   - -------------------------------------- 3.4/109.3 MB 963.2 kB/s eta 0:01:50\n",
      "   - -------------------------------------- 3.7/109.3 MB 960.8 kB/s eta 0:01:50\n",
      "   - -------------------------------------- 3.7/109.3 MB 960.8 kB/s eta 0:01:50\n",
      "   - -------------------------------------- 3.9/109.3 MB 962.8 kB/s eta 0:01:50\n",
      "   - -------------------------------------- 4.2/109.3 MB 964.2 kB/s eta 0:01:49\n",
      "   - -------------------------------------- 4.5/109.3 MB 955.2 kB/s eta 0:01:50\n",
      "   - -------------------------------------- 4.5/109.3 MB 955.2 kB/s eta 0:01:50\n",
      "   - -------------------------------------- 4.7/109.3 MB 960.2 kB/s eta 0:01:49\n",
      "   - -------------------------------------- 5.0/109.3 MB 961.8 kB/s eta 0:01:49\n",
      "   - -------------------------------------- 5.2/109.3 MB 957.3 kB/s eta 0:01:49\n",
      "   -- ------------------------------------- 5.5/109.3 MB 961.5 kB/s eta 0:01:48\n",
      "   -- ------------------------------------- 5.5/109.3 MB 961.5 kB/s eta 0:01:48\n",
      "   -- ------------------------------------- 5.8/109.3 MB 954.7 kB/s eta 0:01:49\n",
      "   -- ------------------------------------- 6.0/109.3 MB 956.3 kB/s eta 0:01:48\n",
      "   -- ------------------------------------- 6.3/109.3 MB 950.4 kB/s eta 0:01:49\n",
      "   -- ------------------------------------- 6.3/109.3 MB 950.4 kB/s eta 0:01:49\n",
      "   -- ------------------------------------- 6.6/109.3 MB 954.1 kB/s eta 0:01:48\n",
      "   -- ------------------------------------- 6.8/109.3 MB 951.0 kB/s eta 0:01:48\n",
      "   -- ------------------------------------- 7.1/109.3 MB 948.3 kB/s eta 0:01:48\n",
      "   -- ------------------------------------- 7.1/109.3 MB 948.3 kB/s eta 0:01:48\n",
      "   -- ------------------------------------- 7.3/109.3 MB 947.6 kB/s eta 0:01:48\n",
      "   -- ------------------------------------- 7.6/109.3 MB 945.1 kB/s eta 0:01:48\n",
      "   -- ------------------------------------- 7.6/109.3 MB 945.1 kB/s eta 0:01:48\n",
      "   -- ------------------------------------- 7.9/109.3 MB 943.0 kB/s eta 0:01:48\n",
      "   -- ------------------------------------- 8.1/109.3 MB 942.5 kB/s eta 0:01:48\n",
      "   --- ------------------------------------ 8.4/109.3 MB 949.1 kB/s eta 0:01:47\n",
      "   --- ------------------------------------ 8.7/109.3 MB 946.9 kB/s eta 0:01:47\n",
      "   --- ------------------------------------ 8.9/109.3 MB 952.9 kB/s eta 0:01:46\n",
      "   --- ------------------------------------ 8.9/109.3 MB 952.9 kB/s eta 0:01:46\n",
      "   --- ------------------------------------ 9.2/109.3 MB 947.6 kB/s eta 0:01:46\n",
      "   --- ------------------------------------ 9.4/109.3 MB 945.6 kB/s eta 0:01:46\n",
      "   --- ------------------------------------ 9.4/109.3 MB 945.6 kB/s eta 0:01:46\n",
      "   --- ------------------------------------ 9.7/109.3 MB 945.2 kB/s eta 0:01:46\n",
      "   --- ----------------------------------- 10.0/109.3 MB 944.8 kB/s eta 0:01:46\n",
      "   --- ----------------------------------- 10.2/109.3 MB 943.1 kB/s eta 0:01:46\n",
      "   --- ----------------------------------- 10.2/109.3 MB 943.1 kB/s eta 0:01:46\n",
      "   --- ----------------------------------- 10.5/109.3 MB 941.5 kB/s eta 0:01:45\n",
      "   --- ----------------------------------- 10.5/109.3 MB 941.5 kB/s eta 0:01:45\n",
      "   --- ----------------------------------- 10.7/109.3 MB 934.6 kB/s eta 0:01:46\n",
      "   --- ----------------------------------- 11.0/109.3 MB 932.1 kB/s eta 0:01:46\n",
      "   --- ----------------------------------- 11.0/109.3 MB 932.1 kB/s eta 0:01:46\n",
      "   ---- ---------------------------------- 11.3/109.3 MB 922.3 kB/s eta 0:01:47\n",
      "   ---- ---------------------------------- 11.3/109.3 MB 922.3 kB/s eta 0:01:47\n",
      "   ---- ---------------------------------- 11.3/109.3 MB 922.3 kB/s eta 0:01:47\n",
      "   ---- ---------------------------------- 11.5/109.3 MB 900.6 kB/s eta 0:01:49\n",
      "   ---- ---------------------------------- 11.5/109.3 MB 900.6 kB/s eta 0:01:49\n",
      "   ---- ---------------------------------- 11.8/109.3 MB 892.6 kB/s eta 0:01:50\n",
      "   ---- ---------------------------------- 12.1/109.3 MB 894.6 kB/s eta 0:01:49\n",
      "   ---- ---------------------------------- 12.3/109.3 MB 900.5 kB/s eta 0:01:48\n",
      "   ---- ---------------------------------- 12.6/109.3 MB 905.3 kB/s eta 0:01:47\n",
      "   ---- ---------------------------------- 12.8/109.3 MB 911.0 kB/s eta 0:01:46\n",
      "   ---- ---------------------------------- 13.1/109.3 MB 916.5 kB/s eta 0:01:45\n",
      "   ---- ---------------------------------- 13.4/109.3 MB 919.8 kB/s eta 0:01:45\n",
      "   ---- ---------------------------------- 13.6/109.3 MB 925.0 kB/s eta 0:01:44\n",
      "   ---- ---------------------------------- 13.9/109.3 MB 929.1 kB/s eta 0:01:43\n",
      "   ----- --------------------------------- 14.2/109.3 MB 935.0 kB/s eta 0:01:42\n",
      "   ----- --------------------------------- 14.4/109.3 MB 937.8 kB/s eta 0:01:42\n",
      "   ----- --------------------------------- 14.7/109.3 MB 943.5 kB/s eta 0:01:41\n",
      "   ----- --------------------------------- 14.9/109.3 MB 949.0 kB/s eta 0:01:40\n",
      "   ----- --------------------------------- 15.2/109.3 MB 953.4 kB/s eta 0:01:39\n",
      "   ----- --------------------------------- 15.5/109.3 MB 957.8 kB/s eta 0:01:38\n",
      "   ----- --------------------------------- 15.5/109.3 MB 957.8 kB/s eta 0:01:38\n",
      "   ----- --------------------------------- 15.7/109.3 MB 948.2 kB/s eta 0:01:39\n",
      "   ----- --------------------------------- 15.7/109.3 MB 948.2 kB/s eta 0:01:39\n",
      "   ----- --------------------------------- 16.0/109.3 MB 940.8 kB/s eta 0:01:40\n",
      "   ----- --------------------------------- 16.3/109.3 MB 939.7 kB/s eta 0:01:39\n",
      "   ----- --------------------------------- 16.3/109.3 MB 939.7 kB/s eta 0:01:39\n",
      "   ----- --------------------------------- 16.5/109.3 MB 934.6 kB/s eta 0:01:40\n",
      "   ----- --------------------------------- 16.8/109.3 MB 930.4 kB/s eta 0:01:40\n",
      "   ------ -------------------------------- 17.0/109.3 MB 934.5 kB/s eta 0:01:39\n",
      "   ------ -------------------------------- 17.3/109.3 MB 937.7 kB/s eta 0:01:39\n",
      "   ------ -------------------------------- 17.3/109.3 MB 937.7 kB/s eta 0:01:39\n",
      "   ------ -------------------------------- 17.3/109.3 MB 937.7 kB/s eta 0:01:39\n",
      "   ------ -------------------------------- 17.6/109.3 MB 924.3 kB/s eta 0:01:40\n",
      "   ------ -------------------------------- 17.8/109.3 MB 923.6 kB/s eta 0:01:40\n",
      "   ------ -------------------------------- 17.8/109.3 MB 923.6 kB/s eta 0:01:40\n",
      "   ------ -------------------------------- 18.1/109.3 MB 922.3 kB/s eta 0:01:39\n",
      "   ------ -------------------------------- 18.1/109.3 MB 922.3 kB/s eta 0:01:39\n",
      "   ------ -------------------------------- 18.4/109.3 MB 915.8 kB/s eta 0:01:40\n",
      "   ------ -------------------------------- 18.6/109.3 MB 912.5 kB/s eta 0:01:40\n",
      "   ------ -------------------------------- 18.6/109.3 MB 912.5 kB/s eta 0:01:40\n",
      "   ------ -------------------------------- 18.9/109.3 MB 911.4 kB/s eta 0:01:40\n",
      "   ------ -------------------------------- 19.1/109.3 MB 913.7 kB/s eta 0:01:39\n",
      "   ------ -------------------------------- 19.4/109.3 MB 917.4 kB/s eta 0:01:38\n",
      "   ------- ------------------------------- 19.7/109.3 MB 921.0 kB/s eta 0:01:38\n",
      "   ------- ------------------------------- 19.9/109.3 MB 921.8 kB/s eta 0:01:37\n",
      "   ------- ------------------------------- 20.2/109.3 MB 925.3 kB/s eta 0:01:37\n",
      "   ------- ------------------------------- 20.4/109.3 MB 928.7 kB/s eta 0:01:36\n",
      "   ------- ------------------------------- 20.7/109.3 MB 931.4 kB/s eta 0:01:36\n",
      "   ------- ------------------------------- 21.0/109.3 MB 934.7 kB/s eta 0:01:35\n",
      "   ------- ------------------------------- 21.2/109.3 MB 937.9 kB/s eta 0:01:34\n",
      "   ------- ------------------------------- 21.5/109.3 MB 940.5 kB/s eta 0:01:34\n",
      "   ------- ------------------------------- 21.8/109.3 MB 942.3 kB/s eta 0:01:33\n",
      "   ------- ------------------------------- 22.0/109.3 MB 944.7 kB/s eta 0:01:33\n",
      "   ------- ------------------------------- 22.3/109.3 MB 947.1 kB/s eta 0:01:32\n",
      "   ------- ------------------------------- 22.3/109.3 MB 947.1 kB/s eta 0:01:32\n",
      "   -------- ------------------------------ 22.5/109.3 MB 949.4 kB/s eta 0:01:32\n",
      "   -------- ------------------------------ 22.8/109.3 MB 952.4 kB/s eta 0:01:31\n",
      "   -------- ------------------------------ 23.1/109.3 MB 950.3 kB/s eta 0:01:31\n",
      "   -------- ------------------------------ 23.1/109.3 MB 950.3 kB/s eta 0:01:31\n",
      "   -------- ------------------------------ 23.3/109.3 MB 948.2 kB/s eta 0:01:31\n",
      "   -------- ------------------------------ 23.6/109.3 MB 947.4 kB/s eta 0:01:31\n",
      "   -------- ------------------------------ 23.9/109.3 MB 946.1 kB/s eta 0:01:31\n",
      "   -------- ------------------------------ 23.9/109.3 MB 946.1 kB/s eta 0:01:31\n",
      "   -------- ------------------------------ 23.9/109.3 MB 946.1 kB/s eta 0:01:31\n",
      "   -------- ------------------------------ 23.9/109.3 MB 946.1 kB/s eta 0:01:31\n",
      "   -------- ------------------------------ 23.9/109.3 MB 946.1 kB/s eta 0:01:31\n",
      "   -------- ------------------------------ 23.9/109.3 MB 946.1 kB/s eta 0:01:31\n",
      "   -------- ------------------------------ 24.9/109.3 MB 942.1 kB/s eta 0:01:30\n",
      "   -------- ------------------------------ 24.9/109.3 MB 942.1 kB/s eta 0:01:30\n",
      "   -------- ------------------------------ 24.9/109.3 MB 942.1 kB/s eta 0:01:30\n",
      "   -------- ------------------------------ 25.2/109.3 MB 933.7 kB/s eta 0:01:31\n",
      "   --------- ----------------------------- 25.4/109.3 MB 931.5 kB/s eta 0:01:31\n",
      "   --------- ----------------------------- 25.4/109.3 MB 931.5 kB/s eta 0:01:31\n",
      "   --------- ----------------------------- 25.7/109.3 MB 929.4 kB/s eta 0:01:30\n",
      "   --------- ----------------------------- 26.0/109.3 MB 928.9 kB/s eta 0:01:30\n",
      "   --------- ----------------------------- 26.0/109.3 MB 928.9 kB/s eta 0:01:30\n",
      "   --------- ----------------------------- 26.2/109.3 MB 926.3 kB/s eta 0:01:30\n",
      "   --------- ----------------------------- 26.2/109.3 MB 926.3 kB/s eta 0:01:30\n",
      "   --------- ----------------------------- 26.5/109.3 MB 922.8 kB/s eta 0:01:30\n",
      "   --------- ----------------------------- 26.7/109.3 MB 923.4 kB/s eta 0:01:30\n",
      "   --------- ----------------------------- 27.0/109.3 MB 924.5 kB/s eta 0:01:29\n",
      "   --------- ----------------------------- 27.3/109.3 MB 927.6 kB/s eta 0:01:29\n",
      "   --------- ----------------------------- 27.3/109.3 MB 927.6 kB/s eta 0:01:29\n",
      "   --------- ----------------------------- 27.5/109.3 MB 925.1 kB/s eta 0:01:29\n",
      "   --------- ----------------------------- 27.5/109.3 MB 925.1 kB/s eta 0:01:29\n",
      "   --------- ----------------------------- 27.8/109.3 MB 922.3 kB/s eta 0:01:29\n",
      "   ---------- ---------------------------- 28.0/109.3 MB 920.8 kB/s eta 0:01:29\n",
      "   ---------- ---------------------------- 28.3/109.3 MB 918.9 kB/s eta 0:01:29\n",
      "   ---------- ---------------------------- 28.3/109.3 MB 918.9 kB/s eta 0:01:29\n",
      "   ---------- ---------------------------- 28.6/109.3 MB 917.5 kB/s eta 0:01:28\n",
      "   ---------- ---------------------------- 28.8/109.3 MB 919.4 kB/s eta 0:01:28\n",
      "   ---------- ---------------------------- 29.1/109.3 MB 921.8 kB/s eta 0:01:27\n",
      "   ---------- ---------------------------- 29.4/109.3 MB 924.7 kB/s eta 0:01:27\n",
      "   ---------- ---------------------------- 29.6/109.3 MB 926.7 kB/s eta 0:01:26\n",
      "   ---------- ---------------------------- 29.9/109.3 MB 927.7 kB/s eta 0:01:26\n",
      "   ---------- ---------------------------- 30.1/109.3 MB 929.6 kB/s eta 0:01:26\n",
      "   ---------- ---------------------------- 30.4/109.3 MB 931.6 kB/s eta 0:01:25\n",
      "   ---------- ---------------------------- 30.7/109.3 MB 932.6 kB/s eta 0:01:25\n",
      "   ----------- --------------------------- 30.9/109.3 MB 936.4 kB/s eta 0:01:24\n",
      "   ----------- --------------------------- 31.2/109.3 MB 940.4 kB/s eta 0:01:24\n",
      "   ----------- --------------------------- 31.5/109.3 MB 942.4 kB/s eta 0:01:23\n",
      "   ----------- --------------------------- 31.7/109.3 MB 944.2 kB/s eta 0:01:23\n",
      "   ----------- --------------------------- 32.0/109.3 MB 946.2 kB/s eta 0:01:22\n",
      "   ----------- --------------------------- 32.2/109.3 MB 948.1 kB/s eta 0:01:22\n",
      "   ----------- --------------------------- 32.5/109.3 MB 949.6 kB/s eta 0:01:21\n",
      "   ----------- --------------------------- 32.8/109.3 MB 953.2 kB/s eta 0:01:21\n",
      "   ----------- --------------------------- 33.0/109.3 MB 955.0 kB/s eta 0:01:20\n",
      "   ----------- --------------------------- 33.3/109.3 MB 956.4 kB/s eta 0:01:20\n",
      "   ----------- --------------------------- 33.6/109.3 MB 957.9 kB/s eta 0:01:20\n",
      "   ------------ -------------------------- 33.8/109.3 MB 960.5 kB/s eta 0:01:19\n",
      "   ------------ -------------------------- 34.1/109.3 MB 962.7 kB/s eta 0:01:19\n",
      "   ------------ -------------------------- 34.3/109.3 MB 963.7 kB/s eta 0:01:18\n",
      "   ------------ -------------------------- 34.6/109.3 MB 966.7 kB/s eta 0:01:18\n",
      "   ------------ -------------------------- 34.9/109.3 MB 968.8 kB/s eta 0:01:17\n",
      "   ------------ -------------------------- 35.1/109.3 MB 970.9 kB/s eta 0:01:17\n",
      "   ------------ -------------------------- 35.4/109.3 MB 971.0 kB/s eta 0:01:17\n",
      "   ------------ -------------------------- 35.4/109.3 MB 971.0 kB/s eta 0:01:17\n",
      "   ------------ -------------------------- 35.7/109.3 MB 969.8 kB/s eta 0:01:16\n",
      "   ------------ -------------------------- 35.9/109.3 MB 970.3 kB/s eta 0:01:16\n",
      "   ------------ -------------------------- 36.2/109.3 MB 969.9 kB/s eta 0:01:16\n",
      "   ------------ -------------------------- 36.2/109.3 MB 969.9 kB/s eta 0:01:16\n",
      "   ------------- ------------------------- 36.4/109.3 MB 969.8 kB/s eta 0:01:16\n",
      "   ------------- ------------------------- 36.4/109.3 MB 969.8 kB/s eta 0:01:16\n",
      "   ------------- ------------------------- 36.7/109.3 MB 966.2 kB/s eta 0:01:16\n",
      "   ------------- ------------------------- 37.0/109.3 MB 965.7 kB/s eta 0:01:15\n",
      "   ------------- ------------------------- 37.0/109.3 MB 965.7 kB/s eta 0:01:15\n",
      "   ------------- ------------------------- 37.2/109.3 MB 963.2 kB/s eta 0:01:15\n",
      "   ------------- ------------------------- 37.2/109.3 MB 963.2 kB/s eta 0:01:15\n",
      "   ------------- ------------------------- 37.2/109.3 MB 963.2 kB/s eta 0:01:15\n",
      "   ------------- ------------------------- 37.2/109.3 MB 963.2 kB/s eta 0:01:15\n",
      "   ------------- ------------------------- 37.2/109.3 MB 963.2 kB/s eta 0:01:15\n",
      "   ------------- ------------------------- 38.3/109.3 MB 962.2 kB/s eta 0:01:14\n",
      "   ------------- ------------------------- 38.3/109.3 MB 962.2 kB/s eta 0:01:14\n",
      "   ------------- ------------------------- 38.3/109.3 MB 962.2 kB/s eta 0:01:14\n",
      "   ------------- ------------------------- 38.5/109.3 MB 952.6 kB/s eta 0:01:15\n",
      "   ------------- ------------------------- 38.8/109.3 MB 954.9 kB/s eta 0:01:14\n",
      "   ------------- ------------------------- 39.1/109.3 MB 957.4 kB/s eta 0:01:14\n",
      "   -------------- ------------------------ 39.3/109.3 MB 962.5 kB/s eta 0:01:13\n",
      "   -------------- ------------------------ 39.6/109.3 MB 963.7 kB/s eta 0:01:13\n",
      "   -------------- ------------------------ 39.8/109.3 MB 967.2 kB/s eta 0:01:12\n",
      "   -------------- ------------------------ 40.1/109.3 MB 973.4 kB/s eta 0:01:12\n",
      "   -------------- ------------------------ 40.4/109.3 MB 975.0 kB/s eta 0:01:11\n",
      "   -------------- ------------------------ 40.6/109.3 MB 986.9 kB/s eta 0:01:10\n",
      "   -------------- ------------------------ 40.9/109.3 MB 989.5 kB/s eta 0:01:10\n",
      "   -------------- ------------------------ 41.2/109.3 MB 991.0 kB/s eta 0:01:09\n",
      "   -------------- ------------------------ 41.4/109.3 MB 998.3 kB/s eta 0:01:08\n",
      "   -------------- ------------------------ 41.7/109.3 MB 999.8 kB/s eta 0:01:08\n",
      "   --------------- ------------------------ 41.9/109.3 MB 1.0 MB/s eta 0:01:08\n",
      "   --------------- ------------------------ 42.2/109.3 MB 1.0 MB/s eta 0:01:07\n",
      "   --------------- ------------------------ 42.5/109.3 MB 1.0 MB/s eta 0:01:07\n",
      "   --------------- ------------------------ 42.7/109.3 MB 1.0 MB/s eta 0:01:07\n",
      "   --------------- ----------------------- 43.0/109.3 MB 997.7 kB/s eta 0:01:07\n",
      "   --------------- ----------------------- 43.0/109.3 MB 997.7 kB/s eta 0:01:07\n",
      "   --------------- ----------------------- 43.3/109.3 MB 992.6 kB/s eta 0:01:07\n",
      "   --------------- ----------------------- 43.5/109.3 MB 990.0 kB/s eta 0:01:07\n",
      "   --------------- ----------------------- 43.5/109.3 MB 990.0 kB/s eta 0:01:07\n",
      "   --------------- ----------------------- 43.8/109.3 MB 984.8 kB/s eta 0:01:07\n",
      "   --------------- ----------------------- 44.0/109.3 MB 980.2 kB/s eta 0:01:07\n",
      "   --------------- ----------------------- 44.0/109.3 MB 980.2 kB/s eta 0:01:07\n",
      "   --------------- ----------------------- 44.3/109.3 MB 971.5 kB/s eta 0:01:07\n",
      "   --------------- ----------------------- 44.6/109.3 MB 973.9 kB/s eta 0:01:07\n",
      "   --------------- ----------------------- 44.8/109.3 MB 975.0 kB/s eta 0:01:07\n",
      "   ---------------- ---------------------- 45.1/109.3 MB 981.7 kB/s eta 0:01:06\n",
      "   ---------------- ---------------------- 45.1/109.3 MB 981.7 kB/s eta 0:01:06\n",
      "   ---------------- ---------------------- 45.4/109.3 MB 981.7 kB/s eta 0:01:06\n",
      "   ---------------- ---------------------- 45.6/109.3 MB 984.8 kB/s eta 0:01:05\n",
      "   ---------------- ---------------------- 45.9/109.3 MB 989.5 kB/s eta 0:01:05\n",
      "   ---------------- ---------------------- 46.1/109.3 MB 987.4 kB/s eta 0:01:04\n",
      "   ---------------- ---------------------- 46.1/109.3 MB 987.4 kB/s eta 0:01:04\n",
      "   ---------------- ---------------------- 46.4/109.3 MB 987.9 kB/s eta 0:01:04\n",
      "   ---------------- ---------------------- 46.7/109.3 MB 982.3 kB/s eta 0:01:04\n",
      "   ---------------- ---------------------- 46.7/109.3 MB 982.3 kB/s eta 0:01:04\n",
      "   ---------------- ---------------------- 46.9/109.3 MB 991.1 kB/s eta 0:01:03\n",
      "   ---------------- ---------------------- 47.2/109.3 MB 992.1 kB/s eta 0:01:03\n",
      "   ---------------- ---------------------- 47.4/109.3 MB 995.2 kB/s eta 0:01:03\n",
      "   ----------------- --------------------- 47.7/109.3 MB 997.7 kB/s eta 0:01:02\n",
      "   ----------------- ---------------------- 48.0/109.3 MB 1.0 MB/s eta 0:01:02\n",
      "   ----------------- ---------------------- 48.2/109.3 MB 1.0 MB/s eta 0:01:01\n",
      "   ----------------- ---------------------- 48.8/109.3 MB 1.0 MB/s eta 0:01:00\n",
      "   ----------------- ---------------------- 49.0/109.3 MB 1.0 MB/s eta 0:01:00\n",
      "   ----------------- ---------------------- 49.0/109.3 MB 1.0 MB/s eta 0:01:00\n",
      "   ------------------ --------------------- 49.3/109.3 MB 1.0 MB/s eta 0:00:59\n",
      "   ------------------ --------------------- 49.5/109.3 MB 1.0 MB/s eta 0:00:59\n",
      "   ------------------ --------------------- 49.5/109.3 MB 1.0 MB/s eta 0:00:59\n",
      "   ------------------ --------------------- 49.8/109.3 MB 1.0 MB/s eta 0:00:59\n",
      "   ------------------ --------------------- 50.1/109.3 MB 1.0 MB/s eta 0:00:59\n",
      "   ------------------ --------------------- 50.1/109.3 MB 1.0 MB/s eta 0:00:59\n",
      "   ----------------- --------------------- 50.3/109.3 MB 998.2 kB/s eta 0:01:00\n",
      "   ----------------- --------------------- 50.3/109.3 MB 998.2 kB/s eta 0:01:00\n",
      "   ------------------ -------------------- 50.6/109.3 MB 993.1 kB/s eta 0:01:00\n",
      "   ------------------ -------------------- 50.9/109.3 MB 989.0 kB/s eta 0:01:00\n",
      "   ------------------ -------------------- 50.9/109.3 MB 989.0 kB/s eta 0:01:00\n",
      "   ------------------ -------------------- 51.1/109.3 MB 983.8 kB/s eta 0:01:00\n",
      "   ------------------ -------------------- 51.4/109.3 MB 979.7 kB/s eta 0:01:00\n",
      "   ------------------ -------------------- 51.4/109.3 MB 979.7 kB/s eta 0:01:00\n",
      "   ------------------ -------------------- 51.6/109.3 MB 974.5 kB/s eta 0:01:00\n",
      "   ------------------ -------------------- 51.6/109.3 MB 974.5 kB/s eta 0:01:00\n",
      "   ------------------ -------------------- 51.9/109.3 MB 970.5 kB/s eta 0:01:00\n",
      "   ------------------ -------------------- 52.2/109.3 MB 970.8 kB/s eta 0:00:59\n",
      "   ------------------ -------------------- 52.2/109.3 MB 970.8 kB/s eta 0:00:59\n",
      "   ------------------ -------------------- 52.4/109.3 MB 970.3 kB/s eta 0:00:59\n",
      "   ------------------ -------------------- 52.7/109.3 MB 970.3 kB/s eta 0:00:59\n",
      "   ------------------ -------------------- 52.7/109.3 MB 970.3 kB/s eta 0:00:59\n",
      "   ------------------ -------------------- 53.0/109.3 MB 969.9 kB/s eta 0:00:59\n",
      "   ------------------ -------------------- 53.0/109.3 MB 969.9 kB/s eta 0:00:59\n",
      "   ------------------ -------------------- 53.0/109.3 MB 969.9 kB/s eta 0:00:59\n",
      "   ------------------ -------------------- 53.0/109.3 MB 969.9 kB/s eta 0:00:59\n",
      "   ------------------ -------------------- 53.0/109.3 MB 969.9 kB/s eta 0:00:59\n",
      "   ------------------- ------------------- 54.0/109.3 MB 997.2 kB/s eta 0:00:56\n",
      "   ------------------- ------------------- 54.0/109.3 MB 997.2 kB/s eta 0:00:56\n",
      "   ------------------- ------------------- 54.3/109.3 MB 974.5 kB/s eta 0:00:57\n",
      "   ------------------- ------------------- 54.5/109.3 MB 979.6 kB/s eta 0:00:56\n",
      "   ------------------- ------------------- 54.8/109.3 MB 981.7 kB/s eta 0:00:56\n",
      "   ------------------- ------------------- 55.1/109.3 MB 986.4 kB/s eta 0:00:55\n",
      "   ------------------- ------------------- 55.3/109.3 MB 988.4 kB/s eta 0:00:55\n",
      "   ------------------- ------------------- 55.8/109.3 MB 996.8 kB/s eta 0:00:54\n",
      "   -------------------- ------------------ 56.1/109.3 MB 999.3 kB/s eta 0:00:54\n",
      "   -------------------- ------------------- 56.4/109.3 MB 1.0 MB/s eta 0:00:53\n",
      "   -------------------- ------------------- 56.6/109.3 MB 1.0 MB/s eta 0:00:53\n",
      "   -------------------- ------------------- 56.9/109.3 MB 1.0 MB/s eta 0:00:52\n",
      "   -------------------- ------------------- 57.1/109.3 MB 1.0 MB/s eta 0:00:52\n",
      "   --------------------- ------------------ 57.4/109.3 MB 1.0 MB/s eta 0:00:52\n",
      "   --------------------- ------------------ 57.7/109.3 MB 1.0 MB/s eta 0:00:51\n",
      "   --------------------- ------------------ 57.9/109.3 MB 1.0 MB/s eta 0:00:51\n",
      "   --------------------- ------------------ 58.2/109.3 MB 1.0 MB/s eta 0:00:50\n",
      "   --------------------- ------------------ 58.5/109.3 MB 1.0 MB/s eta 0:00:50\n",
      "   --------------------- ------------------ 58.7/109.3 MB 1.0 MB/s eta 0:00:50\n",
      "   --------------------- ------------------ 59.0/109.3 MB 1.0 MB/s eta 0:00:49\n",
      "   --------------------- ------------------ 59.2/109.3 MB 1.0 MB/s eta 0:00:49\n",
      "   --------------------- ------------------ 59.5/109.3 MB 1.0 MB/s eta 0:00:49\n",
      "   --------------------- ------------------ 59.8/109.3 MB 1.0 MB/s eta 0:00:48\n",
      "   --------------------- ------------------ 60.0/109.3 MB 1.0 MB/s eta 0:00:48\n",
      "   ---------------------- ----------------- 60.3/109.3 MB 1.0 MB/s eta 0:00:48\n",
      "   ---------------------- ----------------- 60.3/109.3 MB 1.0 MB/s eta 0:00:48\n",
      "   ---------------------- ----------------- 60.6/109.3 MB 1.0 MB/s eta 0:00:48\n",
      "   ---------------------- ----------------- 60.8/109.3 MB 1.0 MB/s eta 0:00:48\n",
      "   ---------------------- ----------------- 61.1/109.3 MB 1.0 MB/s eta 0:00:48\n",
      "   ---------------------- ----------------- 61.1/109.3 MB 1.0 MB/s eta 0:00:48\n",
      "   ---------------------- ----------------- 61.6/109.3 MB 1.0 MB/s eta 0:00:47\n",
      "   ---------------------- ----------------- 61.6/109.3 MB 1.0 MB/s eta 0:00:47\n",
      "   ---------------------- ----------------- 61.9/109.3 MB 1.0 MB/s eta 0:00:47\n",
      "   ---------------------- ----------------- 62.1/109.3 MB 1.0 MB/s eta 0:00:47\n",
      "   ---------------------- ----------------- 62.4/109.3 MB 1.0 MB/s eta 0:00:47\n",
      "   ---------------------- ----------------- 62.7/109.3 MB 1.0 MB/s eta 0:00:46\n",
      "   ----------------------- ---------------- 62.9/109.3 MB 1.0 MB/s eta 0:00:46\n",
      "   ----------------------- ---------------- 62.9/109.3 MB 1.0 MB/s eta 0:00:46\n",
      "   ----------------------- ---------------- 63.2/109.3 MB 1.0 MB/s eta 0:00:46\n",
      "   ----------------------- ---------------- 63.4/109.3 MB 1.0 MB/s eta 0:00:46\n",
      "   ----------------------- ---------------- 63.7/109.3 MB 1.0 MB/s eta 0:00:46\n",
      "   ----------------------- ---------------- 63.7/109.3 MB 1.0 MB/s eta 0:00:46\n",
      "   ----------------------- ---------------- 64.0/109.3 MB 1.0 MB/s eta 0:00:46\n",
      "   ---------------------- ---------------- 64.2/109.3 MB 998.7 kB/s eta 0:00:46\n",
      "   ---------------------- ---------------- 64.2/109.3 MB 998.7 kB/s eta 0:00:46\n",
      "   ----------------------- --------------- 64.5/109.3 MB 996.7 kB/s eta 0:00:45\n",
      "   ----------------------- --------------- 64.7/109.3 MB 996.1 kB/s eta 0:00:45\n",
      "   ----------------------- --------------- 65.0/109.3 MB 994.6 kB/s eta 0:00:45\n",
      "   ----------------------- --------------- 65.3/109.3 MB 996.1 kB/s eta 0:00:45\n",
      "   ----------------------- --------------- 65.3/109.3 MB 996.1 kB/s eta 0:00:45\n",
      "   ----------------------- --------------- 65.5/109.3 MB 995.2 kB/s eta 0:00:44\n",
      "   ----------------------- --------------- 65.8/109.3 MB 992.6 kB/s eta 0:00:44\n",
      "   ----------------------- --------------- 66.1/109.3 MB 996.2 kB/s eta 0:00:44\n",
      "   ----------------------- --------------- 66.3/109.3 MB 997.7 kB/s eta 0:00:44\n",
      "   ------------------------ --------------- 66.6/109.3 MB 1.0 MB/s eta 0:00:43\n",
      "   ------------------------ --------------- 66.8/109.3 MB 1.0 MB/s eta 0:00:43\n",
      "   ------------------------ --------------- 67.1/109.3 MB 1.0 MB/s eta 0:00:42\n",
      "   ------------------------ --------------- 67.4/109.3 MB 1.0 MB/s eta 0:00:42\n",
      "   ------------------------ --------------- 67.6/109.3 MB 1.0 MB/s eta 0:00:40\n",
      "   ------------------------ --------------- 67.9/109.3 MB 1.0 MB/s eta 0:00:40\n",
      "   ------------------------ --------------- 68.2/109.3 MB 1.0 MB/s eta 0:00:40\n",
      "   ------------------------- -------------- 68.4/109.3 MB 1.0 MB/s eta 0:00:39\n",
      "   ------------------------- -------------- 68.7/109.3 MB 1.1 MB/s eta 0:00:39\n",
      "   ------------------------- -------------- 68.9/109.3 MB 1.1 MB/s eta 0:00:39\n",
      "   ------------------------- -------------- 69.2/109.3 MB 1.0 MB/s eta 0:00:39\n",
      "   ------------------------- -------------- 69.5/109.3 MB 1.0 MB/s eta 0:00:39\n",
      "   ------------------------- -------------- 69.7/109.3 MB 1.0 MB/s eta 0:00:38\n",
      "   ------------------------- -------------- 70.0/109.3 MB 1.0 MB/s eta 0:00:38\n",
      "   ------------------------- -------------- 70.3/109.3 MB 1.0 MB/s eta 0:00:38\n",
      "   ------------------------- -------------- 70.3/109.3 MB 1.0 MB/s eta 0:00:38\n",
      "   ------------------------- -------------- 70.5/109.3 MB 1.0 MB/s eta 0:00:38\n",
      "   ------------------------- -------------- 70.8/109.3 MB 1.0 MB/s eta 0:00:38\n",
      "   ------------------------- -------------- 70.8/109.3 MB 1.0 MB/s eta 0:00:38\n",
      "   -------------------------- ------------- 71.0/109.3 MB 1.0 MB/s eta 0:00:38\n",
      "   -------------------------- ------------- 71.3/109.3 MB 1.0 MB/s eta 0:00:37\n",
      "   -------------------------- ------------- 71.6/109.3 MB 1.0 MB/s eta 0:00:37\n",
      "   -------------------------- ------------- 71.8/109.3 MB 1.0 MB/s eta 0:00:37\n",
      "   -------------------------- ------------- 72.1/109.3 MB 1.0 MB/s eta 0:00:37\n",
      "   -------------------------- ------------- 72.4/109.3 MB 1.0 MB/s eta 0:00:36\n",
      "   -------------------------- ------------- 72.4/109.3 MB 1.0 MB/s eta 0:00:36\n",
      "   -------------------------- ------------- 72.6/109.3 MB 1.0 MB/s eta 0:00:36\n",
      "   -------------------------- ------------- 72.9/109.3 MB 1.0 MB/s eta 0:00:36\n",
      "   -------------------------- ------------- 72.9/109.3 MB 1.0 MB/s eta 0:00:36\n",
      "   -------------------------- ------------- 72.9/109.3 MB 1.0 MB/s eta 0:00:36\n",
      "   -------------------------- ------------- 72.9/109.3 MB 1.0 MB/s eta 0:00:36\n",
      "   -------------------------- ------------- 72.9/109.3 MB 1.0 MB/s eta 0:00:36\n",
      "   -------------------------- ------------- 72.9/109.3 MB 1.0 MB/s eta 0:00:36\n",
      "   -------------------------- ------------- 72.9/109.3 MB 1.0 MB/s eta 0:00:36\n",
      "   --------------------------- ------------ 74.4/109.3 MB 1.0 MB/s eta 0:00:34\n",
      "   --------------------------- ------------ 74.7/109.3 MB 1.0 MB/s eta 0:00:34\n",
      "   --------------------------- ------------ 74.7/109.3 MB 1.0 MB/s eta 0:00:34\n",
      "   --------------------------- ------------ 75.0/109.3 MB 1.0 MB/s eta 0:00:34\n",
      "   --------------------------- ------------ 75.0/109.3 MB 1.0 MB/s eta 0:00:34\n",
      "   --------------------------- ------------ 75.2/109.3 MB 1.0 MB/s eta 0:00:34\n",
      "   --------------------------- ------------ 75.5/109.3 MB 1.0 MB/s eta 0:00:33\n",
      "   --------------------------- ------------ 75.8/109.3 MB 1.0 MB/s eta 0:00:33\n",
      "   --------------------------- ------------ 75.8/109.3 MB 1.0 MB/s eta 0:00:33\n",
      "   --------------------------- ------------ 76.0/109.3 MB 1.0 MB/s eta 0:00:33\n",
      "   --------------------------- ------------ 76.3/109.3 MB 1.0 MB/s eta 0:00:33\n",
      "   ---------------------------- ----------- 76.5/109.3 MB 1.0 MB/s eta 0:00:33\n",
      "   ---------------------------- ----------- 76.5/109.3 MB 1.0 MB/s eta 0:00:33\n",
      "   ---------------------------- ----------- 76.8/109.3 MB 1.0 MB/s eta 0:00:32\n",
      "   ---------------------------- ----------- 77.1/109.3 MB 1.0 MB/s eta 0:00:32\n",
      "   ---------------------------- ----------- 77.3/109.3 MB 1.0 MB/s eta 0:00:32\n",
      "   ---------------------------- ----------- 77.3/109.3 MB 1.0 MB/s eta 0:00:32\n",
      "   ---------------------------- ----------- 77.6/109.3 MB 1.0 MB/s eta 0:00:32\n",
      "   ---------------------------- ----------- 77.9/109.3 MB 1.0 MB/s eta 0:00:31\n",
      "   ---------------------------- ----------- 78.1/109.3 MB 1.0 MB/s eta 0:00:31\n",
      "   ---------------------------- ----------- 78.4/109.3 MB 1.0 MB/s eta 0:00:31\n",
      "   ---------------------------- ----------- 78.4/109.3 MB 1.0 MB/s eta 0:00:31\n",
      "   ---------------------------- ----------- 78.6/109.3 MB 1.0 MB/s eta 0:00:31\n",
      "   ---------------------------- ----------- 78.9/109.3 MB 1.0 MB/s eta 0:00:31\n",
      "   ---------------------------- ----------- 79.2/109.3 MB 1.0 MB/s eta 0:00:30\n",
      "   ----------------------------- ---------- 79.4/109.3 MB 1.0 MB/s eta 0:00:30\n",
      "   ----------------------------- ---------- 79.7/109.3 MB 1.0 MB/s eta 0:00:30\n",
      "   ----------------------------- ---------- 80.0/109.3 MB 1.0 MB/s eta 0:00:29\n",
      "   ----------------------------- ---------- 80.0/109.3 MB 1.0 MB/s eta 0:00:29\n",
      "   ----------------------------- ---------- 80.2/109.3 MB 1.0 MB/s eta 0:00:29\n",
      "   ----------------------------- ---------- 80.2/109.3 MB 1.0 MB/s eta 0:00:29\n",
      "   ----------------------------- ---------- 80.5/109.3 MB 1.0 MB/s eta 0:00:29\n",
      "   ----------------------------- ---------- 80.7/109.3 MB 1.0 MB/s eta 0:00:29\n",
      "   ----------------------------- ---------- 80.7/109.3 MB 1.0 MB/s eta 0:00:29\n",
      "   ----------------------------- ---------- 80.7/109.3 MB 1.0 MB/s eta 0:00:29\n",
      "   ----------------------------- ---------- 80.7/109.3 MB 1.0 MB/s eta 0:00:29\n",
      "   ----------------------------- ---------- 80.7/109.3 MB 1.0 MB/s eta 0:00:29\n",
      "   ----------------------------- ---------- 80.7/109.3 MB 1.0 MB/s eta 0:00:29\n",
      "   ----------------------------- ---------- 80.7/109.3 MB 1.0 MB/s eta 0:00:29\n",
      "   ------------------------------ --------- 82.3/109.3 MB 1.0 MB/s eta 0:00:27\n",
      "   ------------------------------ --------- 82.6/109.3 MB 1.0 MB/s eta 0:00:26\n",
      "   ------------------------------ --------- 82.6/109.3 MB 1.0 MB/s eta 0:00:26\n",
      "   ------------------------------ --------- 82.8/109.3 MB 1.0 MB/s eta 0:00:26\n",
      "   ------------------------------ --------- 83.1/109.3 MB 1.0 MB/s eta 0:00:26\n",
      "   ------------------------------ --------- 83.1/109.3 MB 1.0 MB/s eta 0:00:26\n",
      "   ------------------------------ --------- 83.4/109.3 MB 1.0 MB/s eta 0:00:26\n",
      "   ------------------------------ --------- 83.4/109.3 MB 1.0 MB/s eta 0:00:26\n",
      "   ------------------------------ --------- 83.6/109.3 MB 1.0 MB/s eta 0:00:25\n",
      "   ------------------------------ --------- 83.9/109.3 MB 1.0 MB/s eta 0:00:25\n",
      "   ------------------------------ --------- 84.1/109.3 MB 1.1 MB/s eta 0:00:24\n",
      "   ------------------------------ --------- 84.1/109.3 MB 1.1 MB/s eta 0:00:24\n",
      "   ------------------------------ --------- 84.4/109.3 MB 1.1 MB/s eta 0:00:24\n",
      "   ------------------------------ --------- 84.7/109.3 MB 1.1 MB/s eta 0:00:24\n",
      "   ------------------------------ --------- 84.7/109.3 MB 1.1 MB/s eta 0:00:24\n",
      "   ------------------------------- -------- 84.9/109.3 MB 1.0 MB/s eta 0:00:24\n",
      "   ------------------------------- -------- 85.2/109.3 MB 1.0 MB/s eta 0:00:24\n",
      "   ------------------------------- -------- 85.5/109.3 MB 1.0 MB/s eta 0:00:24\n",
      "   ------------------------------- -------- 85.7/109.3 MB 1.0 MB/s eta 0:00:23\n",
      "   ------------------------------- -------- 86.0/109.3 MB 1.0 MB/s eta 0:00:23\n",
      "   ------------------------------- -------- 86.0/109.3 MB 1.0 MB/s eta 0:00:23\n",
      "   ------------------------------- -------- 86.2/109.3 MB 1.0 MB/s eta 0:00:23\n",
      "   ------------------------------- -------- 86.2/109.3 MB 1.0 MB/s eta 0:00:23\n",
      "   ------------------------------- -------- 86.5/109.3 MB 1.0 MB/s eta 0:00:23\n",
      "   ------------------------------- -------- 86.8/109.3 MB 1.0 MB/s eta 0:00:23\n",
      "   ------------------------------- -------- 86.8/109.3 MB 1.0 MB/s eta 0:00:23\n",
      "   ------------------------------- -------- 87.0/109.3 MB 1.0 MB/s eta 0:00:23\n",
      "   ------------------------------- -------- 87.3/109.3 MB 1.0 MB/s eta 0:00:22\n",
      "   -------------------------------- ------- 87.6/109.3 MB 1.0 MB/s eta 0:00:22\n",
      "   -------------------------------- ------- 87.6/109.3 MB 1.0 MB/s eta 0:00:22\n",
      "   ------------------------------- ------- 87.8/109.3 MB 998.8 kB/s eta 0:00:22\n",
      "   ------------------------------- ------- 88.1/109.3 MB 996.1 kB/s eta 0:00:22\n",
      "   ------------------------------- ------- 88.3/109.3 MB 990.5 kB/s eta 0:00:22\n",
      "   ------------------------------- ------- 88.6/109.3 MB 990.0 kB/s eta 0:00:21\n",
      "   ------------------------------- ------- 88.9/109.3 MB 990.5 kB/s eta 0:00:21\n",
      "   ------------------------------- ------- 89.1/109.3 MB 989.0 kB/s eta 0:00:21\n",
      "   ------------------------------- ------- 89.1/109.3 MB 989.0 kB/s eta 0:00:21\n",
      "   ------------------------------- ------- 89.4/109.3 MB 983.3 kB/s eta 0:00:21\n",
      "   ------------------------------- ------- 89.7/109.3 MB 984.3 kB/s eta 0:00:20\n",
      "   -------------------------------- ------ 89.9/109.3 MB 987.4 kB/s eta 0:00:20\n",
      "   -------------------------------- ------ 90.2/109.3 MB 989.0 kB/s eta 0:00:20\n",
      "   -------------------------------- ------ 90.4/109.3 MB 992.6 kB/s eta 0:00:19\n",
      "   -------------------------------- ------ 90.7/109.3 MB 995.2 kB/s eta 0:00:19\n",
      "   -------------------------------- ------ 90.7/109.3 MB 995.2 kB/s eta 0:00:19\n",
      "   -------------------------------- ------ 91.0/109.3 MB 993.6 kB/s eta 0:00:19\n",
      "   -------------------------------- ------ 91.2/109.3 MB 991.0 kB/s eta 0:00:19\n",
      "   -------------------------------- ------ 91.5/109.3 MB 987.9 kB/s eta 0:00:19\n",
      "   -------------------------------- ------ 91.5/109.3 MB 987.9 kB/s eta 0:00:19\n",
      "   -------------------------------- ------ 91.8/109.3 MB 989.5 kB/s eta 0:00:18\n",
      "   -------------------------------- ------ 92.0/109.3 MB 984.3 kB/s eta 0:00:18\n",
      "   -------------------------------- ------ 92.3/109.3 MB 989.0 kB/s eta 0:00:18\n",
      "   --------------------------------- ----- 92.5/109.3 MB 989.0 kB/s eta 0:00:17\n",
      "   --------------------------------- ----- 92.8/109.3 MB 992.0 kB/s eta 0:00:17\n",
      "   --------------------------------- ----- 93.1/109.3 MB 994.7 kB/s eta 0:00:17\n",
      "   --------------------------------- ----- 93.3/109.3 MB 993.1 kB/s eta 0:00:17\n",
      "   --------------------------------- ----- 93.3/109.3 MB 993.1 kB/s eta 0:00:17\n",
      "   --------------------------------- ----- 93.6/109.3 MB 992.0 kB/s eta 0:00:16\n",
      "   --------------------------------- ----- 93.8/109.3 MB 993.6 kB/s eta 0:00:16\n",
      "   --------------------------------- ----- 93.8/109.3 MB 993.6 kB/s eta 0:00:16\n",
      "   --------------------------------- ----- 94.1/109.3 MB 992.6 kB/s eta 0:00:16\n",
      "   --------------------------------- ----- 94.4/109.3 MB 991.0 kB/s eta 0:00:16\n",
      "   --------------------------------- ----- 94.6/109.3 MB 992.1 kB/s eta 0:00:15\n",
      "   --------------------------------- ----- 94.6/109.3 MB 992.1 kB/s eta 0:00:15\n",
      "   --------------------------------- ----- 94.9/109.3 MB 988.9 kB/s eta 0:00:15\n",
      "   --------------------------------- ----- 95.2/109.3 MB 992.6 kB/s eta 0:00:15\n",
      "   ---------------------------------- ---- 95.4/109.3 MB 995.2 kB/s eta 0:00:14\n",
      "   ---------------------------------- ---- 95.4/109.3 MB 995.2 kB/s eta 0:00:14\n",
      "   ---------------------------------- ---- 95.4/109.3 MB 995.2 kB/s eta 0:00:14\n",
      "   ---------------------------------- ---- 95.4/109.3 MB 995.2 kB/s eta 0:00:14\n",
      "   ---------------------------------- ---- 95.4/109.3 MB 995.2 kB/s eta 0:00:14\n",
      "   ---------------------------------- ---- 95.4/109.3 MB 995.2 kB/s eta 0:00:14\n",
      "   ---------------------------------- ---- 96.2/109.3 MB 969.9 kB/s eta 0:00:14\n",
      "   ---------------------------------- ---- 96.2/109.3 MB 969.9 kB/s eta 0:00:14\n",
      "   ---------------------------------- ---- 96.2/109.3 MB 969.9 kB/s eta 0:00:14\n",
      "   ---------------------------------- ---- 97.3/109.3 MB 980.7 kB/s eta 0:00:13\n",
      "   ---------------------------------- ---- 97.8/109.3 MB 983.3 kB/s eta 0:00:12\n",
      "   ---------------------------------- ---- 97.8/109.3 MB 983.3 kB/s eta 0:00:12\n",
      "   ---------------------------------- ---- 98.0/109.3 MB 982.2 kB/s eta 0:00:12\n",
      "   ----------------------------------- --- 98.3/109.3 MB 980.2 kB/s eta 0:00:12\n",
      "   ----------------------------------- --- 98.6/109.3 MB 978.7 kB/s eta 0:00:11\n",
      "   ----------------------------------- --- 98.6/109.3 MB 978.7 kB/s eta 0:00:11\n",
      "   ----------------------------------- --- 98.8/109.3 MB 974.5 kB/s eta 0:00:11\n",
      "   ----------------------------------- --- 99.1/109.3 MB 973.0 kB/s eta 0:00:11\n",
      "   ----------------------------------- --- 99.4/109.3 MB 970.4 kB/s eta 0:00:11\n",
      "   ----------------------------------- --- 99.6/109.3 MB 971.9 kB/s eta 0:00:10\n",
      "   ----------------------------------- --- 99.6/109.3 MB 971.9 kB/s eta 0:00:10\n",
      "   ----------------------------------- --- 99.9/109.3 MB 972.5 kB/s eta 0:00:10\n",
      "   ---------------------------------- --- 100.1/109.3 MB 974.5 kB/s eta 0:00:10\n",
      "   ---------------------------------- --- 100.4/109.3 MB 972.5 kB/s eta 0:00:10\n",
      "   ---------------------------------- --- 100.4/109.3 MB 972.5 kB/s eta 0:00:10\n",
      "   ----------------------------------- -- 100.7/109.3 MB 966.7 kB/s eta 0:00:09\n",
      "   ----------------------------------- -- 100.9/109.3 MB 964.7 kB/s eta 0:00:09\n",
      "   ----------------------------------- -- 101.2/109.3 MB 967.7 kB/s eta 0:00:09\n",
      "   ----------------------------------- -- 101.4/109.3 MB 970.5 kB/s eta 0:00:09\n",
      "   ----------------------------------- -- 101.7/109.3 MB 975.5 kB/s eta 0:00:08\n",
      "   ----------------------------------- -- 102.0/109.3 MB 979.6 kB/s eta 0:00:08\n",
      "   ----------------------------------- -- 102.2/109.3 MB 979.2 kB/s eta 0:00:08\n",
      "   ------------------------------------- -- 102.5/109.3 MB 1.0 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 102.5/109.3 MB 1.0 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 102.8/109.3 MB 1.0 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 103.0/109.3 MB 1.0 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 103.3/109.3 MB 1.0 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 103.3/109.3 MB 1.0 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 103.5/109.3 MB 1.0 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 103.5/109.3 MB 1.0 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 103.5/109.3 MB 1.0 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 103.5/109.3 MB 1.0 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 103.5/109.3 MB 1.0 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 103.5/109.3 MB 1.0 MB/s eta 0:00:06\n",
      "   ------------------------------------ - 105.1/109.3 MB 983.8 kB/s eta 0:00:05\n",
      "   ------------------------------------ - 105.4/109.3 MB 985.9 kB/s eta 0:00:04\n",
      "   ------------------------------------ - 105.4/109.3 MB 985.9 kB/s eta 0:00:04\n",
      "   ------------------------------------ - 105.6/109.3 MB 984.3 kB/s eta 0:00:04\n",
      "   ------------------------------------ - 105.9/109.3 MB 984.8 kB/s eta 0:00:04\n",
      "   ------------------------------------ - 106.2/109.3 MB 988.0 kB/s eta 0:00:04\n",
      "   ------------------------------------ - 106.2/109.3 MB 988.0 kB/s eta 0:00:04\n",
      "   -------------------------------------  106.4/109.3 MB 987.4 kB/s eta 0:00:03\n",
      "   -------------------------------------  106.7/109.3 MB 987.4 kB/s eta 0:00:03\n",
      "   -------------------------------------  107.0/109.3 MB 987.9 kB/s eta 0:00:03\n",
      "   -------------------------------------  107.0/109.3 MB 987.9 kB/s eta 0:00:03\n",
      "   -------------------------------------  107.2/109.3 MB 987.9 kB/s eta 0:00:03\n",
      "   -------------------------------------  107.5/109.3 MB 984.8 kB/s eta 0:00:02\n",
      "   -------------------------------------  107.7/109.3 MB 981.7 kB/s eta 0:00:02\n",
      "   -------------------------------------  108.0/109.3 MB 985.9 kB/s eta 0:00:02\n",
      "   -------------------------------------  108.0/109.3 MB 985.9 kB/s eta 0:00:02\n",
      "   -------------------------------------  108.3/109.3 MB 988.5 kB/s eta 0:00:02\n",
      "   -------------------------------------  108.5/109.3 MB 984.3 kB/s eta 0:00:01\n",
      "   -------------------------------------  108.5/109.3 MB 984.3 kB/s eta 0:00:01\n",
      "   -------------------------------------  108.8/109.3 MB 981.7 kB/s eta 0:00:01\n",
      "   -------------------------------------  109.1/109.3 MB 978.7 kB/s eta 0:00:01\n",
      "   -------------------------------------  109.1/109.3 MB 978.7 kB/s eta 0:00:01\n",
      "   -------------------------------------- 109.3/109.3 MB 969.8 kB/s eta 0:00:00\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.0 MB 1.0 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.8/12.0 MB 1.1 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 1.0/12.0 MB 1.1 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 1.3/12.0 MB 1.1 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 1.6/12.0 MB 1.1 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 1.6/12.0 MB 1.1 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.8/12.0 MB 1.1 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 2.1/12.0 MB 1.1 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 2.4/12.0 MB 1.1 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 2.6/12.0 MB 1.1 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 2.9/12.0 MB 1.1 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 3.1/12.0 MB 1.1 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 3.7/12.0 MB 1.2 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 3.9/12.0 MB 1.2 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 4.2/12.0 MB 1.2 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 4.5/12.0 MB 1.2 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 4.5/12.0 MB 1.2 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 4.7/12.0 MB 1.1 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 5.2/12.0 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.5/12.0 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.5/12.0 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.8/12.0 MB 1.2 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 6.3/12.0 MB 1.2 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 6.6/12.0 MB 1.2 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 6.6/12.0 MB 1.2 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 6.8/12.0 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 7.3/12.0 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 7.6/12.0 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 7.6/12.0 MB 1.2 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 7.9/12.0 MB 1.2 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 8.1/12.0 MB 1.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 8.7/12.0 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.9/12.0 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.9/12.0 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 9.2/12.0 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 9.7/12.0 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 10.0/12.0 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 10.2/12.0 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 10.2/12.0 MB 1.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 10.7/12.0 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 11.0/12.0 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.3/12.0 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.5/12.0 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.8/12.0 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 1.2 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/6.3 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/6.3 MB 1.1 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 0.8/6.3 MB 1.2 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.0/6.3 MB 1.3 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 1.3/6.3 MB 1.2 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 1.6/6.3 MB 1.2 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 1.6/6.3 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 2.1/6.3 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 2.4/6.3 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 2.6/6.3 MB 1.2 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 2.6/6.3 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 2.9/6.3 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 3.1/6.3 MB 1.1 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 3.4/6.3 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 3.7/6.3 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 3.7/6.3 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 3.9/6.3 MB 1.1 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 4.2/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 4.5/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 4.7/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 4.7/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 4.7/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 4.7/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 4.7/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 4.7/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 4.7/6.3 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------------------- 6.3/6.3 MB 1.1 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.7 MB 932.9 kB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 958.5 kB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.0/2.7 MB 1.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.3/2.7 MB 1.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 1.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 1.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 2.1/2.7 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.1/2.7 MB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.4/2.7 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: sympy, safetensors, torch, tokenizers, transformers, sentence-transformers\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "Successfully installed safetensors-0.6.2 sentence-transformers-5.1.2 sympy-1.14.0 tokenizers-0.22.1 torch-2.9.0 transformers-4.57.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64f7b772-b4c0-45dc-9963-5c280cdfbbcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\activations_tf.py:22\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\__init__.py:15\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     export_dynamic_quantized_onnx_model,\n\u001b[0;32m     12\u001b[0m     export_optimized_onnx_model,\n\u001b[0;32m     13\u001b[0m     export_static_quantized_openvino_model,\n\u001b[0;32m     14\u001b[0m )\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     CrossEncoder,\n\u001b[0;32m     17\u001b[0m     CrossEncoderModelCardData,\n\u001b[0;32m     18\u001b[0m     CrossEncoderTrainer,\n\u001b[0;32m     19\u001b[0m     CrossEncoderTrainingArguments,\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoggingHandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_card\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderModelCardData\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainer\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_onnx_model, load_openvino_model\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfit_mixin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FitMixin\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_card\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderModelCardData, generate_model_card\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     32\u001b[0m     cross_encoder_init_args_decorator,\n\u001b[0;32m     33\u001b[0m     cross_encoder_predict_rank_args_decorator,\n\u001b[0;32m     34\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\fit_mixin.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenization_utils_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BatchEncoding\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining_args\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoderTrainingArguments\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mNoDuplicatesDataLoader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NoDuplicatesDataLoader\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceLabelDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceLabelDataset\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceEvaluator\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\datasets\\__init__.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDenoisingAutoEncoderDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DenoisingAutoEncoderDataset\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mNoDuplicatesDataLoader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NoDuplicatesDataLoader\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mParallelSentencesDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentenceLabelDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceLabelDataset\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSentencesDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentencesDataset\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\datasets\\ParallelSentencesDataset.py:19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputExample\n\u001b[0;32m     22\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:36\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_module_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_class_from_dynamic_module, get_relative_import_files\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_card\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformerModelCardData, generate_model_card\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Router\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mModule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sentence_transformers\\model_card.py:26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautonotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainerCallback\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CodeCarbonCallback\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodelcard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_markdown_table\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer_callback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainerControl, TrainerState\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2317\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2315\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module:\n\u001b[0;32m   2316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2317\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m   2318\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   2319\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2347\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   2345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   2346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 2347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2345\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   2343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   2344\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2345\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   2346\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\integrations\\integration_utils.py:60\u001b[0m\n\u001b[0;32m     57\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tf_available():\n\u001b[1;32m---> 60\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TFPreTrainedModel\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2317\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2315\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module:\n\u001b[0;32m   2316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2317\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m   2318\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   2319\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2347\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   2345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   2346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 2347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2345\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   2343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   2344\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2345\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   2346\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:38\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataCollatorWithPadding, DefaultDataCollator\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations_tf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tf_activation\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_module_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m custom_object_save\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\activations_tf.py:27\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse(keras\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour currently installed version of Keras is Keras 3, but this is not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers. Please install the backwards-compatible tf-keras package with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tf-keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m         )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gelu\u001b[39m(x):\n\u001b[0;32m     35\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m    Gaussian Error Linear Unit. Original Implementation of the gelu activation function in Google Bert repo when\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m    initially created. For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3)))) Also see\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    https://huggingface.co/papers/1606.08415\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`."
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Create embeddings for the combined text\n",
    "df['combined_text'] = df['Description_cleaned'].apply(lambda x: ' '.join(x)) + ' ' + \\\n",
    "                      df['Patient_cleaned'].apply(lambda x: ' '.join(x)) + ' ' + \\\n",
    "                      df['Doctor_cleaned'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = model.encode(df['combined_text'], show_progress_bar=True)\n",
    "\n",
    "# embeddings is a NumPy array you can use for clustering, similarity, or ML\n",
    "embeddings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2ed9fd87-d118-42a8-bded-e0653cd5fe8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256916, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Combine relevant columns into one text field\n",
    "df['combined_text'] = df['Description_cleaned'].apply(lambda x: ' '.join(x)) + ' ' + \\\n",
    "                      df['Patient_cleaned'].apply(lambda x: ' '.join(x)) + ' ' + \\\n",
    "                      df['Doctor_cleaned'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Create TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "     max_features=1000,   # instead of 5000\n",
    "    stop_words='english',\n",
    "    ngram_range=(1,2)\n",
    ")\n",
    "\n",
    "# Fit and transform\n",
    "X_tfidf = tfidf.fit_transform(df['combined_text'])\n",
    "\n",
    "print(X_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a33d1-3f8f-4e0a-b8e8-9a5bb317ea22",
   "metadata": {
    "id": "008a33d1-3f8f-4e0a-b8e8-9a5bb317ea22"
   },
   "source": [
    "**Text Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96de91a-cf0f-4dc3-9dc3-7c8c9a7c2daf",
   "metadata": {
    "id": "f96de91a-cf0f-4dc3-9dc3-7c8c9a7c2daf"
   },
   "source": [
    "Finally, we normalize the text by joining the processed tokens back into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e892765-2534-4e4c-92a2-10fc7fe75c63",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4e892765-2534-4e4c-92a2-10fc7fe75c63",
    "outputId": "7946d807-935c-42cf-9e9e-4c240598fa01"
   },
   "outputs": [],
   "source": [
    "# Convert token lists to cleaned strings\n",
    "for col in ['Description_cleaned', 'Patient_cleaned', 'Doctor_cleaned']:\n",
    "    df[col.replace('_tokens', '_cleaned')] = df[col].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Display the first few rows\n",
    "df[['Description_cleaned', 'Patient_cleaned', 'Doctor_cleaned']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e896532-f251-4271-b203-b1fa3ef9f485",
   "metadata": {
    "id": "5e896532-f251-4271-b203-b1fa3ef9f485"
   },
   "outputs": [],
   "source": [
    "### **Exploratory Data Analysis (EDA)**\n",
    "# Word Frequency Distribution for Patient messages\n",
    "all_patient_words = [word for tokens in df['Patient_cleaned'] for word in tokens]\n",
    "freq_dist_patient = FreqDist(all_patient_words)\n",
    "most_common_patient = freq_dist_patient.most_common(20)\n",
    "# Plotting the most common words\n",
    "words, counts = zip(*most_common_patient)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(words, counts)\n",
    "plt.title('Most Common Words in Patient Messages')\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc146e0-bbf1-4c23-8f4a-5a20f80ac6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31e8ea8-0140-4dc7-8a0c-36553b767516",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "id": "d31e8ea8-0140-4dc7-8a0c-36553b767516",
    "outputId": "4ee18857-43c9-4797-b480-49010fb36593"
   },
   "outputs": [],
   "source": [
    "# Word Frequency Distribution for Doctor messages\n",
    "all_doctor_words = [word for tokens in df['Doctor_cleaned'] for word in tokens]\n",
    "freq_dist_doctor = FreqDist(all_doctor_words)\n",
    "most_common_doctor = freq_dist_doctor.most_common(20)\n",
    "# Plotting the most common words\n",
    "words, counts = zip(*most_common_doctor)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(words, counts)\n",
    "plt.title('Most Common Words in Doctor Messages')\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba95b634-90c1-4dbe-92c5-2c4b16178b59",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "ba95b634-90c1-4dbe-92c5-2c4b16178b59",
    "outputId": "4e00c1c9-35c0-43d9-c162-861b19a67a3e"
   },
   "outputs": [],
   "source": [
    "\n",
    "### **Visualization of Message Lengths**\n",
    "# Calculate message lengths\n",
    "df['Patient_msg_length'] = df['Patient_cleaned'].apply(len)\n",
    "df['Doctor_msg_length'] = df['Doctor_cleaned'].apply(len)\n",
    "\n",
    "# Plotting the message lengths\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(df['Patient_msg_length'], bins=30, alpha=0.5, label='Patient Messages')\n",
    "plt.hist(df['Doctor_msg_length'], bins=30, alpha=0.5, label='Doctor Messages')\n",
    "plt.title('Distribution of Message Lengths')\n",
    "plt.xlabel('Message Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NHFQmuJekM7m",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NHFQmuJekM7m",
    "outputId": "671593a6-a77f-4878-eae0-1ce37ee64e12"
   },
   "outputs": [],
   "source": [
    "# Create new columns for text length in words\n",
    "for col in ['Description_cleaned', 'Patient_cleaned', 'Doctor_cleaned']:\n",
    "    df[col + '_length'] = df[col].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Plot word count distribution for each text column\n",
    "for col in ['Description_cleaned', 'Patient_cleaned', 'Doctor_cleaned']:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.histplot(df[col + '_length'], bins=30, kde=True, color='teal')\n",
    "    plt.title(f\"Word Count Distribution in {col}\")\n",
    "    plt.xlabel(\"Word Count\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fstyKC6vWAj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 631
    },
    "id": "6fstyKC6vWAj",
    "outputId": "bd27b376-0a81-42d9-c71a-6a9687199357"
   },
   "outputs": [],
   "source": [
    "# ploting common pair of words in patient and doctor messages\n",
    "from nltk import bigrams\n",
    "from collections import Counter\n",
    "patient_bigrams = [bigram for tokens in df['Patient_cleaned'] for bigram in bigrams(tokens)]\n",
    "doctor_bigrams = [bigram for tokens in df['Doctor_cleaned'] for bigram in bigrams(tokens)]\n",
    "patient_bigram_counts = Counter(patient_bigrams).most_common(20)\n",
    "doctor_bigram_counts = Counter(doctor_bigrams).most_common(20)\n",
    "# Plotting Patient Bigrams\n",
    "patient_bigrams_words, patient_bigrams_counts = zip(*patient_bigram_counts)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar([' '.join(bigram) for bigram in patient_bigrams_words], patient_bigrams_counts)\n",
    "plt.title('Most Common Bigrams in Patient Messages')\n",
    "plt.xlabel('Bigrams')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wLJHyM0QxUJb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wLJHyM0QxUJb",
    "outputId": "20c2067d-2068-4401-d083-22fdea86904d"
   },
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8007a543-855d-4737-acd0-54c575a72683",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df['Patient_cleaned'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HLfnPIvJwkv7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "HLfnPIvJwkv7",
    "outputId": "c4299040-9307-4013-f3be-10c6ac88530b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ploting wordcloud for doctor and patient messages\n",
    "from wordcloud import WordCloud\n",
    "# Generate wordcloud for Patient messages\n",
    "patient_text = ' '.join(df['Patient_cleaned'])\n",
    "patient_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(patient_text)\n",
    "# Plotting the wordcloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(patient_wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud for Patient Messages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee09e031-d262-4b15-9d6c-b7a8413a1287",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfb2cf6-391d-4009-889d-76f404236ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  FEATURE EXTRACTION using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df['combined_text'])\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3434d983-4de1-4f56-83b1-15fa38014fed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V5E1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
