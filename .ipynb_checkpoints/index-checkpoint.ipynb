{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3a13801-58a2-4e19-b13f-bc28cd0488ef",
   "metadata": {},
   "source": [
    "# DAKTARI- THE AI MEDICAL CHATBOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcae89a-931f-4799-a25a-c04c0ae95640",
   "metadata": {},
   "source": [
    "# PROJECT SUMMARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e7485d-48cb-4955-87fb-552f56e91e2f",
   "metadata": {},
   "source": [
    "# 1. BUSINESS UNDERSTANDING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f702a413-97f5-4b72-93a6-65103c750b3d",
   "metadata": {},
   "source": [
    "# 2. BUSINESS PROBLEM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1626f89b-4590-4bae-a63e-8133c52f3b94",
   "metadata": {},
   "source": [
    "# 3. OBJECTIVES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a5bc1c-49db-4d3a-80ee-d40ee7580bcf",
   "metadata": {},
   "source": [
    "## 3.1 Main objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc9ca01-2799-4196-9026-b4ab29aa99d9",
   "metadata": {},
   "source": [
    "## 3.2 Specific objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e5bbbd-efa9-40e6-906a-0f2433a76d87",
   "metadata": {},
   "source": [
    "## 3.3 Research Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caec4643-06a9-4c1f-99b9-71750c6d3dad",
   "metadata": {},
   "source": [
    "## 3.4 Metric of success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4143d22c-6b0e-44b3-a9fe-6e2d6495fefd",
   "metadata": {},
   "source": [
    "# 4. DATA UNDERSTANDING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4950e8d-8103-4dab-ab08-8fce263a6208",
   "metadata": {},
   "source": [
    "## 4.1 Data Limitation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f1574e-6de8-4f95-987f-a93bbc79b7d9",
   "metadata": {},
   "source": [
    "# 5. DATA EXPLORATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c857b6-60e7-4aad-8dd4-5f25b29403a6",
   "metadata": {},
   "source": [
    "## 5.1 Loading a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe9421d-6ce8-4af4-ab83-d6e87d8822bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b285469-1be8-411e-b00f-042ecd720406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\users\\user\\anaconda3\\lib\\site-packages (0.36.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface_hub) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface_hub) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (2025.4.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ade30278-8cf9-4e36-aac6-5786c6e594de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Patient</th>\n",
       "      <th>Doctor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q. What does abutment of the nerve root mean?</td>\n",
       "      <td>Hi doctor,I am just wondering what is abutting...</td>\n",
       "      <td>Hi. I have gone through your query with dilige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q. What should I do to reduce my weight gained...</td>\n",
       "      <td>Hi doctor, I am a 22-year-old female who was d...</td>\n",
       "      <td>Hi. You have really done well with the hypothy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q. I have started to get lots of acne on my fa...</td>\n",
       "      <td>Hi doctor! I used to have clear skin but since...</td>\n",
       "      <td>Hi there Acne has multifactorial etiology. Onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q. Why do I have uncomfortable feeling between...</td>\n",
       "      <td>Hello doctor,I am having an uncomfortable feel...</td>\n",
       "      <td>Hello. The popping and discomfort what you fel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q. My symptoms after intercourse threatns me e...</td>\n",
       "      <td>Hello doctor,Before two years had sex with a c...</td>\n",
       "      <td>Hello. The HIV test uses a finger prick blood ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description  \\\n",
       "0      Q. What does abutment of the nerve root mean?   \n",
       "1  Q. What should I do to reduce my weight gained...   \n",
       "2  Q. I have started to get lots of acne on my fa...   \n",
       "3  Q. Why do I have uncomfortable feeling between...   \n",
       "4  Q. My symptoms after intercourse threatns me e...   \n",
       "\n",
       "                                             Patient  \\\n",
       "0  Hi doctor,I am just wondering what is abutting...   \n",
       "1  Hi doctor, I am a 22-year-old female who was d...   \n",
       "2  Hi doctor! I used to have clear skin but since...   \n",
       "3  Hello doctor,I am having an uncomfortable feel...   \n",
       "4  Hello doctor,Before two years had sex with a c...   \n",
       "\n",
       "                                              Doctor  \n",
       "0  Hi. I have gone through your query with dilige...  \n",
       "1  Hi. You have really done well with the hypothy...  \n",
       "2  Hi there Acne has multifactorial etiology. Onl...  \n",
       "3  Hello. The popping and discomfort what you fel...  \n",
       "4  Hello. The HIV test uses a finger prick blood ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"hf://datasets/DrBenjamin/ai-medical-chatbot/dialogues.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bead0f63-e1a9-4802-af46-157ab49df77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256916, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c6370c9-721e-419a-8dde-09aad81ee379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 256916 entries, 0 to 256915\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   Description  256916 non-null  object\n",
      " 1   Patient      256916 non-null  object\n",
      " 2   Doctor       256916 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc85deae-6f16-4b0f-8159-eb2e1201138a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Description    0\n",
       "Patient        0\n",
       "Doctor         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105154fb-6afe-4744-b883-60ea0779603b",
   "metadata": {},
   "source": [
    "Since our data is not missing any missing values we can move to cleaning the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82dbf8d-c837-46e1-9c3a-18a2984e349e",
   "metadata": {},
   "source": [
    "## 5.2 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f72e8e9d-99e3-4f25-8442-845e84d1b79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk # natural language toolkit\n",
    "import re # regular expressions\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import FreqDist\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad4f1c85-5d9c-4f52-b4f8-88b07c8f713b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary resources\n",
    "nltk.download('punkt') \n",
    "nltk.download('stopwords') \n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae875b5-53f1-45ce-b5f9-f20bab148201",
   "metadata": {},
   "source": [
    "### 5.2.1 Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7521dba3-6eaf-4b60-a54c-6aa8f3fbd166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Description', 'Patient', 'Doctor'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7758501-1e4c-4733-9861-1c5a6840eef3",
   "metadata": {},
   "source": [
    "**Tokenization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99baa13e-7d22-4b70-af1d-777ad8722b55",
   "metadata": {},
   "source": [
    "Let's breaks down each text into a list of words **tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "937a2e5a-85f8-4839-99ce-60cf5e1615fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description_tokens</th>\n",
       "      <th>Patient_tokens</th>\n",
       "      <th>Doctor_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Q, ., What, does, abutment, of, the, nerve, r...</td>\n",
       "      <td>[Hi, doctor, ,, I, am, just, wondering, what, ...</td>\n",
       "      <td>[Hi, ., I, have, gone, through, your, query, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Q, ., What, should, I, do, to, reduce, my, we...</td>\n",
       "      <td>[Hi, doctor, ,, I, am, a, 22-year-old, female,...</td>\n",
       "      <td>[Hi, ., You, have, really, done, well, with, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Q., I, have, started, to, get, lots, of, acne...</td>\n",
       "      <td>[Hi, doctor, !, I, used, to, have, clear, skin...</td>\n",
       "      <td>[Hi, there, Acne, has, multifactorial, etiolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Q, ., Why, do, I, have, uncomfortable, feelin...</td>\n",
       "      <td>[Hello, doctor, ,, I, am, having, an, uncomfor...</td>\n",
       "      <td>[Hello, ., The, popping, and, discomfort, what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Q, ., My, symptoms, after, intercourse, threa...</td>\n",
       "      <td>[Hello, doctor, ,, Before, two, years, had, se...</td>\n",
       "      <td>[Hello, ., The, HIV, test, uses, a, finger, pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Description_tokens  \\\n",
       "0  [Q, ., What, does, abutment, of, the, nerve, r...   \n",
       "1  [Q, ., What, should, I, do, to, reduce, my, we...   \n",
       "2  [Q., I, have, started, to, get, lots, of, acne...   \n",
       "3  [Q, ., Why, do, I, have, uncomfortable, feelin...   \n",
       "4  [Q, ., My, symptoms, after, intercourse, threa...   \n",
       "\n",
       "                                      Patient_tokens  \\\n",
       "0  [Hi, doctor, ,, I, am, just, wondering, what, ...   \n",
       "1  [Hi, doctor, ,, I, am, a, 22-year-old, female,...   \n",
       "2  [Hi, doctor, !, I, used, to, have, clear, skin...   \n",
       "3  [Hello, doctor, ,, I, am, having, an, uncomfor...   \n",
       "4  [Hello, doctor, ,, Before, two, years, had, se...   \n",
       "\n",
       "                                       Doctor_tokens  \n",
       "0  [Hi, ., I, have, gone, through, your, query, w...  \n",
       "1  [Hi, ., You, have, really, done, well, with, t...  \n",
       "2  [Hi, there, Acne, has, multifactorial, etiolog...  \n",
       "3  [Hello, ., The, popping, and, discomfort, what...  \n",
       "4  [Hello, ., The, HIV, test, uses, a, finger, pr...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply tokenization to each text column\n",
    "for col in ['Description', 'Patient', 'Doctor']:\n",
    "    df[col + '_tokens'] = df[col].astype(str).apply(word_tokenize)\n",
    "\n",
    "df[['Description_tokens', 'Patient_tokens', 'Doctor_tokens']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d5c55d-c354-4d94-85a3-2fb7c1492f8b",
   "metadata": {},
   "source": [
    "**Lowercasing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ba2516-787c-484c-96a3-b54623ed0f96",
   "metadata": {},
   "source": [
    "Let's convert our tokenized text to **lowercase** to ensure consistency in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d2c9719-309d-4e31-ad6d-fedaad528518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description_tokens</th>\n",
       "      <th>Patient_tokens</th>\n",
       "      <th>Doctor_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[q, ., what, does, abutment, of, the, nerve, r...</td>\n",
       "      <td>[hi, doctor, ,, i, am, just, wondering, what, ...</td>\n",
       "      <td>[hi, ., i, have, gone, through, your, query, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[q, ., what, should, i, do, to, reduce, my, we...</td>\n",
       "      <td>[hi, doctor, ,, i, am, a, 22-year-old, female,...</td>\n",
       "      <td>[hi, ., you, have, really, done, well, with, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[q., i, have, started, to, get, lots, of, acne...</td>\n",
       "      <td>[hi, doctor, !, i, used, to, have, clear, skin...</td>\n",
       "      <td>[hi, there, acne, has, multifactorial, etiolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[q, ., why, do, i, have, uncomfortable, feelin...</td>\n",
       "      <td>[hello, doctor, ,, i, am, having, an, uncomfor...</td>\n",
       "      <td>[hello, ., the, popping, and, discomfort, what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[q, ., my, symptoms, after, intercourse, threa...</td>\n",
       "      <td>[hello, doctor, ,, before, two, years, had, se...</td>\n",
       "      <td>[hello, ., the, hiv, test, uses, a, finger, pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Description_tokens  \\\n",
       "0  [q, ., what, does, abutment, of, the, nerve, r...   \n",
       "1  [q, ., what, should, i, do, to, reduce, my, we...   \n",
       "2  [q., i, have, started, to, get, lots, of, acne...   \n",
       "3  [q, ., why, do, i, have, uncomfortable, feelin...   \n",
       "4  [q, ., my, symptoms, after, intercourse, threa...   \n",
       "\n",
       "                                      Patient_tokens  \\\n",
       "0  [hi, doctor, ,, i, am, just, wondering, what, ...   \n",
       "1  [hi, doctor, ,, i, am, a, 22-year-old, female,...   \n",
       "2  [hi, doctor, !, i, used, to, have, clear, skin...   \n",
       "3  [hello, doctor, ,, i, am, having, an, uncomfor...   \n",
       "4  [hello, doctor, ,, before, two, years, had, se...   \n",
       "\n",
       "                                       Doctor_tokens  \n",
       "0  [hi, ., i, have, gone, through, your, query, w...  \n",
       "1  [hi, ., you, have, really, done, well, with, t...  \n",
       "2  [hi, there, acne, has, multifactorial, etiolog...  \n",
       "3  [hello, ., the, popping, and, discomfort, what...  \n",
       "4  [hello, ., the, hiv, test, uses, a, finger, pr...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert all tokens to lowercase\n",
    "for col in ['Description_tokens', 'Patient_tokens', 'Doctor_tokens']:\n",
    "    df[col] = df[col].apply(lambda x: [word.lower() for word in x])\n",
    "\n",
    "df[['Description_tokens', 'Patient_tokens', 'Doctor_tokens']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b5905f-2065-45a0-99ad-ef6e2595a449",
   "metadata": {},
   "source": [
    "**Stopword Removal**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa30510-86a0-4a5b-b222-4d5f53c19733",
   "metadata": {},
   "source": [
    "By removing **Stopwords** like *the, is, and*   which don’t really  carry meaningful information we reduce the noise in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab9797b-6fc6-4736-b6a7-759a94ed6761",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Remove stopwords\n",
    "for col in ['Description_tokens', 'Patient_tokens', 'Doctor_tokens']:\n",
    "    df[col] = df[col].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "df[['Description_tokens', 'Patient_tokens', 'Doctor_tokens']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c94db7-f2eb-4528-b138-3c73ce23c2e2",
   "metadata": {},
   "source": [
    "**Punctuation Removal**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcab456-3150-45e3-a780-b1842bcc00c6",
   "metadata": {},
   "source": [
    "Removing punctuation marks like *!, ., ,*  because they rarely add semantic meaning in our text analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c9686c-7b81-4fa9-a54e-70d61e252fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "for col in ['Description_tokens', 'Patient_tokens', 'Doctor_tokens']:\n",
    "    df[col] = df[col].apply(lambda x: [word for word in x if word not in string.punctuation])\n",
    "\n",
    "df[['Description_tokens', 'Patient_tokens', 'Doctor_tokens']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e80d47a-e610-47d8-a868-a296078e7bd1",
   "metadata": {},
   "source": [
    "**Stemming and Lemmatization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53215ce-b58f-4c28-8291-b62380a0c76a",
   "metadata": {},
   "source": [
    "**Stemming** reduces words to their base forms e.g running to run.\n",
    "\n",
    "**Lemmatization** refines this using linguistic context better to good.\n",
    "Both this steps will help us unify variations of the same word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51761fdb-75eb-4352-a215-e55b1442ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def stem_and_lemmatize(tokens):\n",
    "    stems = [stemmer.stem(word) for word in tokens]\n",
    "    lemmas = [lemmatizer.lemmatize(word) for word in stems]\n",
    "    return lemmas\n",
    "\n",
    "# Apply to each column\n",
    "for col in ['Description_tokens', 'Patient_tokens', 'Doctor_tokens']:\n",
    "    df[col] = df[col].apply(stem_and_lemmatize)\n",
    "\n",
    "df[['Description_tokens', 'Patient_tokens', 'Doctor_tokens']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a33d1-3f8f-4e0a-b8e8-9a5bb317ea22",
   "metadata": {},
   "source": [
    "**Text Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96de91a-cf0f-4dc3-9dc3-7c8c9a7c2daf",
   "metadata": {},
   "source": [
    "Finally, we normalize the text by joining the processed tokens back into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e892765-2534-4e4c-92a2-10fc7fe75c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rejoin tokens into cleaned text\n",
    "for col in ['Description_tokens', 'Patient_tokens', 'Doctor_tokens']:\n",
    "    df[col + '_cleaned'] = df[col].apply(lambda x: ' '.join(x))\n",
    "\n",
    "df[['Description_cleaned', 'Patient_cleaned', 'Patient_cleaned']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e896532-f251-4271-b203-b1fa3ef9f485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31e8ea8-0140-4dc7-8a0c-36553b767516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba95b634-90c1-4dbe-92c5-2c4b16178b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780210fb-a7f2-4512-8d45-292ea9fdac81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f006d9a-8b7f-4546-9b09-0307e9a912cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
