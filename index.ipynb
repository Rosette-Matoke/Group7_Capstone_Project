{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3a13801-58a2-4e19-b13f-bc28cd0488ef",
   "metadata": {
    "id": "a3a13801-58a2-4e19-b13f-bc28cd0488ef"
   },
   "source": [
    "# DAKTARI- THE AI MEDICAL CHATBOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcae89a-931f-4799-a25a-c04c0ae95640",
   "metadata": {
    "id": "cdcae89a-931f-4799-a25a-c04c0ae95640"
   },
   "source": [
    "# PROJECT SUMMARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e7485d-48cb-4955-87fb-552f56e91e2f",
   "metadata": {
    "id": "64e7485d-48cb-4955-87fb-552f56e91e2f"
   },
   "source": [
    "# 1. BUSINESS UNDERSTANDING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f702a413-97f5-4b72-93a6-65103c750b3d",
   "metadata": {
    "id": "f702a413-97f5-4b72-93a6-65103c750b3d"
   },
   "source": [
    "# 2. BUSINESS PROBLEM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1626f89b-4590-4bae-a63e-8133c52f3b94",
   "metadata": {
    "id": "1626f89b-4590-4bae-a63e-8133c52f3b94"
   },
   "source": [
    "# 3. OBJECTIVES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a5bc1c-49db-4d3a-80ee-d40ee7580bcf",
   "metadata": {
    "id": "20a5bc1c-49db-4d3a-80ee-d40ee7580bcf"
   },
   "source": [
    "## 3.1 Main objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc9ca01-2799-4196-9026-b4ab29aa99d9",
   "metadata": {
    "id": "2fc9ca01-2799-4196-9026-b4ab29aa99d9"
   },
   "source": [
    "## 3.2 Specific objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e5bbbd-efa9-40e6-906a-0f2433a76d87",
   "metadata": {
    "id": "d9e5bbbd-efa9-40e6-906a-0f2433a76d87"
   },
   "source": [
    "## 3.3 Research Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caec4643-06a9-4c1f-99b9-71750c6d3dad",
   "metadata": {
    "id": "caec4643-06a9-4c1f-99b9-71750c6d3dad"
   },
   "source": [
    "## 3.4 Metric of success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4143d22c-6b0e-44b3-a9fe-6e2d6495fefd",
   "metadata": {
    "id": "4143d22c-6b0e-44b3-a9fe-6e2d6495fefd"
   },
   "source": [
    "# 4. DATA UNDERSTANDING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4950e8d-8103-4dab-ab08-8fce263a6208",
   "metadata": {
    "id": "f4950e8d-8103-4dab-ab08-8fce263a6208"
   },
   "source": [
    "## 4.1 Data Limitation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f1574e-6de8-4f95-987f-a93bbc79b7d9",
   "metadata": {
    "id": "e8f1574e-6de8-4f95-987f-a93bbc79b7d9"
   },
   "source": [
    "# 5. DATA EXPLORATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c857b6-60e7-4aad-8dd4-5f25b29403a6",
   "metadata": {
    "id": "e8c857b6-60e7-4aad-8dd4-5f25b29403a6"
   },
   "source": [
    "## 5.1 Loading a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbe9421d-6ce8-4af4-ab83-d6e87d8822bb",
   "metadata": {
    "id": "bbe9421d-6ce8-4af4-ab83-d6e87d8822bb"
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b285469-1be8-411e-b00f-042ecd720406",
   "metadata": {
    "id": "6b285469-1be8-411e-b00f-042ecd720406"
   },
   "outputs": [],
   "source": [
    "# pip install huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ade30278-8cf9-4e36-aac6-5786c6e594de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ade30278-8cf9-4e36-aac6-5786c6e594de",
    "outputId": "2d39bf3f-0a8f-4452-dd6d-6a0b6ea7131f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Patient</th>\n",
       "      <th>Doctor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q. What does abutment of the nerve root mean?</td>\n",
       "      <td>Hi doctor,I am just wondering what is abutting...</td>\n",
       "      <td>Hi. I have gone through your query with dilige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q. What should I do to reduce my weight gained...</td>\n",
       "      <td>Hi doctor, I am a 22-year-old female who was d...</td>\n",
       "      <td>Hi. You have really done well with the hypothy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q. I have started to get lots of acne on my fa...</td>\n",
       "      <td>Hi doctor! I used to have clear skin but since...</td>\n",
       "      <td>Hi there Acne has multifactorial etiology. Onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q. Why do I have uncomfortable feeling between...</td>\n",
       "      <td>Hello doctor,I am having an uncomfortable feel...</td>\n",
       "      <td>Hello. The popping and discomfort what you fel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q. My symptoms after intercourse threatns me e...</td>\n",
       "      <td>Hello doctor,Before two years had sex with a c...</td>\n",
       "      <td>Hello. The HIV test uses a finger prick blood ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Description  \\\n",
       "0      Q. What does abutment of the nerve root mean?   \n",
       "1  Q. What should I do to reduce my weight gained...   \n",
       "2  Q. I have started to get lots of acne on my fa...   \n",
       "3  Q. Why do I have uncomfortable feeling between...   \n",
       "4  Q. My symptoms after intercourse threatns me e...   \n",
       "\n",
       "                                             Patient  \\\n",
       "0  Hi doctor,I am just wondering what is abutting...   \n",
       "1  Hi doctor, I am a 22-year-old female who was d...   \n",
       "2  Hi doctor! I used to have clear skin but since...   \n",
       "3  Hello doctor,I am having an uncomfortable feel...   \n",
       "4  Hello doctor,Before two years had sex with a c...   \n",
       "\n",
       "                                              Doctor  \n",
       "0  Hi. I have gone through your query with dilige...  \n",
       "1  Hi. You have really done well with the hypothy...  \n",
       "2  Hi there Acne has multifactorial etiology. Onl...  \n",
       "3  Hello. The popping and discomfort what you fel...  \n",
       "4  Hello. The HIV test uses a finger prick blood ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"hf://datasets/DrBenjamin/ai-medical-chatbot/dialogues.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bead0f63-e1a9-4802-af46-157ab49df77e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bead0f63-e1a9-4802-af46-157ab49df77e",
    "outputId": "21f414dc-f3a2-4802-f552-9406f2858aba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256916, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c6370c9-721e-419a-8dde-09aad81ee379",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1c6370c9-721e-419a-8dde-09aad81ee379",
    "outputId": "322307ee-df06-4b30-f2b6-c3c314c2971a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 256916 entries, 0 to 256915\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   Description  256916 non-null  object\n",
      " 1   Patient      256916 non-null  object\n",
      " 2   Doctor       256916 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc85deae-6f16-4b0f-8159-eb2e1201138a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "bc85deae-6f16-4b0f-8159-eb2e1201138a",
    "outputId": "e793f6ec-55be-4c29-f2a4-76482e9a8655"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Description    0\n",
       "Patient        0\n",
       "Doctor         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105154fb-6afe-4744-b883-60ea0779603b",
   "metadata": {
    "id": "105154fb-6afe-4744-b883-60ea0779603b"
   },
   "source": [
    "Since our data is not missing any missing values we can move to cleaning the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82dbf8d-c837-46e1-9c3a-18a2984e349e",
   "metadata": {
    "id": "f82dbf8d-c837-46e1-9c3a-18a2984e349e"
   },
   "source": [
    "## 5.2 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f72e8e9d-99e3-4f25-8442-845e84d1b79d",
   "metadata": {
    "id": "f72e8e9d-99e3-4f25-8442-845e84d1b79d"
   },
   "outputs": [],
   "source": [
    "import nltk # natural language toolkit\n",
    "import re # regular expressions\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import FreqDist\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad4f1c85-5d9c-4f52-b4f8-88b07c8f713b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ad4f1c85-5d9c-4f52-b4f8-88b07c8f713b",
    "outputId": "af95897f-6c3f-4f68-bb98-884965159f7a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Halla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Halla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Halla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Halla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae875b5-53f1-45ce-b5f9-f20bab148201",
   "metadata": {
    "id": "9ae875b5-53f1-45ce-b5f9-f20bab148201"
   },
   "source": [
    "### 5.2.1 Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7521dba3-6eaf-4b60-a54c-6aa8f3fbd166",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7521dba3-6eaf-4b60-a54c-6aa8f3fbd166",
    "outputId": "fb889870-b46c-40a0-e6a5-588d05b7cbaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Description', 'Patient', 'Doctor'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7758501-1e4c-4733-9861-1c5a6840eef3",
   "metadata": {
    "id": "d7758501-1e4c-4733-9861-1c5a6840eef3"
   },
   "source": [
    "**Tokenization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99baa13e-7d22-4b70-af1d-777ad8722b55",
   "metadata": {
    "id": "99baa13e-7d22-4b70-af1d-777ad8722b55"
   },
   "source": [
    "Let's breaks down each text into a list of words **tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "937a2e5a-85f8-4839-99ce-60cf5e1615fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "937a2e5a-85f8-4839-99ce-60cf5e1615fa",
    "outputId": "d0378cad-2917-4439-ce2c-fe03eb6183f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Halla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Halla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description_cleaned</th>\n",
       "      <th>Patient_cleaned</th>\n",
       "      <th>Doctor_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Q, ., What, does, abutment, of, the, nerve, r...</td>\n",
       "      <td>[Hi, doctor, ,, I, am, just, wondering, what, ...</td>\n",
       "      <td>[Hi, ., I, have, gone, through, your, query, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Q, ., What, should, I, do, to, reduce, my, we...</td>\n",
       "      <td>[Hi, doctor, ,, I, am, a, 22-year-old, female,...</td>\n",
       "      <td>[Hi, ., You, have, really, done, well, with, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Q., I, have, started, to, get, lots, of, acne...</td>\n",
       "      <td>[Hi, doctor, !, I, used, to, have, clear, skin...</td>\n",
       "      <td>[Hi, there, Acne, has, multifactorial, etiolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Q, ., Why, do, I, have, uncomfortable, feelin...</td>\n",
       "      <td>[Hello, doctor, ,, I, am, having, an, uncomfor...</td>\n",
       "      <td>[Hello, ., The, popping, and, discomfort, what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Q, ., My, symptoms, after, intercourse, threa...</td>\n",
       "      <td>[Hello, doctor, ,, Before, two, years, had, se...</td>\n",
       "      <td>[Hello, ., The, HIV, test, uses, a, finger, pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Description_cleaned  \\\n",
       "0  [Q, ., What, does, abutment, of, the, nerve, r...   \n",
       "1  [Q, ., What, should, I, do, to, reduce, my, we...   \n",
       "2  [Q., I, have, started, to, get, lots, of, acne...   \n",
       "3  [Q, ., Why, do, I, have, uncomfortable, feelin...   \n",
       "4  [Q, ., My, symptoms, after, intercourse, threa...   \n",
       "\n",
       "                                     Patient_cleaned  \\\n",
       "0  [Hi, doctor, ,, I, am, just, wondering, what, ...   \n",
       "1  [Hi, doctor, ,, I, am, a, 22-year-old, female,...   \n",
       "2  [Hi, doctor, !, I, used, to, have, clear, skin...   \n",
       "3  [Hello, doctor, ,, I, am, having, an, uncomfor...   \n",
       "4  [Hello, doctor, ,, Before, two, years, had, se...   \n",
       "\n",
       "                                      Doctor_cleaned  \n",
       "0  [Hi, ., I, have, gone, through, your, query, w...  \n",
       "1  [Hi, ., You, have, really, done, well, with, t...  \n",
       "2  [Hi, there, Acne, has, multifactorial, etiolog...  \n",
       "3  [Hello, ., The, popping, and, discomfort, what...  \n",
       "4  [Hello, ., The, HIV, test, uses, a, finger, pr...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply tokenization to each text column\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "for col in ['Description', 'Patient', 'Doctor']:\n",
    "    df[col + '_cleaned'] = df[col].astype(str).apply(word_tokenize)\n",
    "\n",
    "df[['Description_cleaned', 'Patient_cleaned', 'Doctor_cleaned']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d5c55d-c354-4d94-85a3-2fb7c1492f8b",
   "metadata": {
    "id": "b0d5c55d-c354-4d94-85a3-2fb7c1492f8b"
   },
   "source": [
    "**Lowercasing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ba2516-787c-484c-96a3-b54623ed0f96",
   "metadata": {
    "id": "e0ba2516-787c-484c-96a3-b54623ed0f96"
   },
   "source": [
    "Let's convert our tokenized text to **lowercase** to ensure consistency in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d2c9719-309d-4e31-ad6d-fedaad528518",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "3d2c9719-309d-4e31-ad6d-fedaad528518",
    "outputId": "3f419d24-5094-4da6-9d4a-d4ab2b73c553"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description_cleaned</th>\n",
       "      <th>Patient_cleaned</th>\n",
       "      <th>Doctor_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[q, ., what, does, abutment, of, the, nerve, r...</td>\n",
       "      <td>[hi, doctor, ,, i, am, just, wondering, what, ...</td>\n",
       "      <td>[hi, ., i, have, gone, through, your, query, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[q, ., what, should, i, do, to, reduce, my, we...</td>\n",
       "      <td>[hi, doctor, ,, i, am, a, 22-year-old, female,...</td>\n",
       "      <td>[hi, ., you, have, really, done, well, with, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[q., i, have, started, to, get, lots, of, acne...</td>\n",
       "      <td>[hi, doctor, !, i, used, to, have, clear, skin...</td>\n",
       "      <td>[hi, there, acne, has, multifactorial, etiolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[q, ., why, do, i, have, uncomfortable, feelin...</td>\n",
       "      <td>[hello, doctor, ,, i, am, having, an, uncomfor...</td>\n",
       "      <td>[hello, ., the, popping, and, discomfort, what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[q, ., my, symptoms, after, intercourse, threa...</td>\n",
       "      <td>[hello, doctor, ,, before, two, years, had, se...</td>\n",
       "      <td>[hello, ., the, hiv, test, uses, a, finger, pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Description_cleaned  \\\n",
       "0  [q, ., what, does, abutment, of, the, nerve, r...   \n",
       "1  [q, ., what, should, i, do, to, reduce, my, we...   \n",
       "2  [q., i, have, started, to, get, lots, of, acne...   \n",
       "3  [q, ., why, do, i, have, uncomfortable, feelin...   \n",
       "4  [q, ., my, symptoms, after, intercourse, threa...   \n",
       "\n",
       "                                     Patient_cleaned  \\\n",
       "0  [hi, doctor, ,, i, am, just, wondering, what, ...   \n",
       "1  [hi, doctor, ,, i, am, a, 22-year-old, female,...   \n",
       "2  [hi, doctor, !, i, used, to, have, clear, skin...   \n",
       "3  [hello, doctor, ,, i, am, having, an, uncomfor...   \n",
       "4  [hello, doctor, ,, before, two, years, had, se...   \n",
       "\n",
       "                                      Doctor_cleaned  \n",
       "0  [hi, ., i, have, gone, through, your, query, w...  \n",
       "1  [hi, ., you, have, really, done, well, with, t...  \n",
       "2  [hi, there, acne, has, multifactorial, etiolog...  \n",
       "3  [hello, ., the, popping, and, discomfort, what...  \n",
       "4  [hello, ., the, hiv, test, uses, a, finger, pr...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert all tokens to lowercase\n",
    "for col in ['Description_cleaned', 'Patient_cleaned', 'Doctor_cleaned']:\n",
    "    df[col] = df[col].apply(lambda x: [word.lower() for word in x])\n",
    "\n",
    "df[['Description_cleaned', 'Patient_cleaned', 'Doctor_cleaned']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b5905f-2065-45a0-99ad-ef6e2595a449",
   "metadata": {
    "id": "46b5905f-2065-45a0-99ad-ef6e2595a449"
   },
   "source": [
    "**Stopword Removal**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa30510-86a0-4a5b-b222-4d5f53c19733",
   "metadata": {
    "id": "9aa30510-86a0-4a5b-b222-4d5f53c19733"
   },
   "source": [
    "By removing **Stopwords** like *the, is, and*   which don’t really  carry meaningful information we reduce the noise in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ab9797b-6fc6-4736-b6a7-759a94ed6761",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "0ab9797b-6fc6-4736-b6a7-759a94ed6761",
    "outputId": "1274accb-6c32-482b-e53b-577cc3cc7509"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description_cleaned</th>\n",
       "      <th>Patient_cleaned</th>\n",
       "      <th>Doctor_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[., abutment, nerve, root, mean, ?]</td>\n",
       "      <td>[,, wondering, abutting, abutment, nerve, root...</td>\n",
       "      <td>[., gone, query, diligence, would, like, know,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[., reduce, weight, gained, due, genetic, hypo...</td>\n",
       "      <td>[,, 22-year-old, female, diagnosed, hypothyroi...</td>\n",
       "      <td>[., really, done, well, hypothyroidism, proble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[q., started, get, lots, acne, face, ,, partic...</td>\n",
       "      <td>[!, used, clear, skin, since, moved, new, plac...</td>\n",
       "      <td>[acne, multifactorial, etiology, ., acne, soap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[., uncomfortable, feeling, middle, spine, lef...</td>\n",
       "      <td>[,, uncomfortable, feeling, middle, spine, lef...</td>\n",
       "      <td>[., popping, discomfort, felt, either, imprope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[., symptoms, intercourse, threatns, even, neg...</td>\n",
       "      <td>[,, two, years, sex, call, girl, dark, locatio...</td>\n",
       "      <td>[., hiv, test, uses, finger, prick, blood, sam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Description_cleaned  \\\n",
       "0                [., abutment, nerve, root, mean, ?]   \n",
       "1  [., reduce, weight, gained, due, genetic, hypo...   \n",
       "2  [q., started, get, lots, acne, face, ,, partic...   \n",
       "3  [., uncomfortable, feeling, middle, spine, lef...   \n",
       "4  [., symptoms, intercourse, threatns, even, neg...   \n",
       "\n",
       "                                     Patient_cleaned  \\\n",
       "0  [,, wondering, abutting, abutment, nerve, root...   \n",
       "1  [,, 22-year-old, female, diagnosed, hypothyroi...   \n",
       "2  [!, used, clear, skin, since, moved, new, plac...   \n",
       "3  [,, uncomfortable, feeling, middle, spine, lef...   \n",
       "4  [,, two, years, sex, call, girl, dark, locatio...   \n",
       "\n",
       "                                      Doctor_cleaned  \n",
       "0  [., gone, query, diligence, would, like, know,...  \n",
       "1  [., really, done, well, hypothyroidism, proble...  \n",
       "2  [acne, multifactorial, etiology, ., acne, soap...  \n",
       "3  [., popping, discomfort, felt, either, imprope...  \n",
       "4  [., hiv, test, uses, finger, prick, blood, sam...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_remove = ['hi', 'hello', 'doctor', 'thanks', 'thank', 'please', 'kindly','q','but']\n",
    "stop_words = set(stopwords.words('english')+ words_to_remove)\n",
    "\n",
    "# Remove stopwords\n",
    "for col in ['Description_cleaned', 'Patient_cleaned', 'Doctor_cleaned']:\n",
    "    df[col] = df[col].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "df[['Description_cleaned', 'Patient_cleaned', 'Doctor_cleaned']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c94db7-f2eb-4528-b138-3c73ce23c2e2",
   "metadata": {
    "id": "38c94db7-f2eb-4528-b138-3c73ce23c2e2"
   },
   "source": [
    "**Punctuation Removal**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcab456-3150-45e3-a780-b1842bcc00c6",
   "metadata": {
    "id": "cfcab456-3150-45e3-a780-b1842bcc00c6"
   },
   "source": [
    "Removing punctuation marks like *!, ., ,*  because they rarely add semantic meaning in our text analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18c9686c-7b81-4fa9-a54e-70d61e252fb5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "18c9686c-7b81-4fa9-a54e-70d61e252fb5",
    "outputId": "35cade20-42db-4bc9-e780-f7ba9523a636"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description_cleaned</th>\n",
       "      <th>Patient_cleaned</th>\n",
       "      <th>Doctor_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[abutment, nerve, root, mean]</td>\n",
       "      <td>[wondering, abutting, abutment, nerve, root, m...</td>\n",
       "      <td>[gone, query, diligence, would, like, know, he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[reduce, weight, gained, due, genetic, hypothy...</td>\n",
       "      <td>[22-year-old, female, diagnosed, hypothyroidis...</td>\n",
       "      <td>[really, done, well, hypothyroidism, problem, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[q., started, get, lots, acne, face, particula...</td>\n",
       "      <td>[used, clear, skin, since, moved, new, place, ...</td>\n",
       "      <td>[acne, multifactorial, etiology, acne, soap, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[uncomfortable, feeling, middle, spine, left, ...</td>\n",
       "      <td>[uncomfortable, feeling, middle, spine, left, ...</td>\n",
       "      <td>[popping, discomfort, felt, either, improper, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[symptoms, intercourse, threatns, even, negati...</td>\n",
       "      <td>[two, years, sex, call, girl, dark, location, ...</td>\n",
       "      <td>[hiv, test, uses, finger, prick, blood, sample...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Description_cleaned  \\\n",
       "0                      [abutment, nerve, root, mean]   \n",
       "1  [reduce, weight, gained, due, genetic, hypothy...   \n",
       "2  [q., started, get, lots, acne, face, particula...   \n",
       "3  [uncomfortable, feeling, middle, spine, left, ...   \n",
       "4  [symptoms, intercourse, threatns, even, negati...   \n",
       "\n",
       "                                     Patient_cleaned  \\\n",
       "0  [wondering, abutting, abutment, nerve, root, m...   \n",
       "1  [22-year-old, female, diagnosed, hypothyroidis...   \n",
       "2  [used, clear, skin, since, moved, new, place, ...   \n",
       "3  [uncomfortable, feeling, middle, spine, left, ...   \n",
       "4  [two, years, sex, call, girl, dark, location, ...   \n",
       "\n",
       "                                      Doctor_cleaned  \n",
       "0  [gone, query, diligence, would, like, know, he...  \n",
       "1  [really, done, well, hypothyroidism, problem, ...  \n",
       "2  [acne, multifactorial, etiology, acne, soap, i...  \n",
       "3  [popping, discomfort, felt, either, improper, ...  \n",
       "4  [hiv, test, uses, finger, prick, blood, sample...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "for col in ['Description_cleaned', 'Patient_cleaned', 'Doctor_cleaned']:\n",
    "    df[col] = df[col].apply(lambda x: [word for word in x if word not in string.punctuation])\n",
    "\n",
    "df[['Description_cleaned', 'Patient_cleaned', 'Doctor_cleaned']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e80d47a-e610-47d8-a868-a296078e7bd1",
   "metadata": {
    "id": "1e80d47a-e610-47d8-a868-a296078e7bd1"
   },
   "source": [
    "**POS Tagging and Lemmatization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53215ce-b58f-4c28-8291-b62380a0c76a",
   "metadata": {
    "id": "d53215ce-b58f-4c28-8291-b62380a0c76a"
   },
   "source": [
    "**POS Tagging** involves labeling each word in a sentence with its grammatical part of speech such as nouns, adjectives, verbs and adjectives\n",
    "\n",
    "**Lemmatization** refines this using linguistic context better to good.\n",
    "Both this steps will help us unify variations of the same word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "89a6a82a-9dd3-42cc-8f51-fd4d05acdc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#POS tagging\n",
    "def get_pos(word):\n",
    "    tag = pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\n",
    "        'J': wordnet.ADJ,  # Represents an Adjective\n",
    "        'N': wordnet.NOUN, # Represents a Noun\n",
    "        'V': wordnet.VERB, # Represents a Verb\n",
    "        'R': wordnet.ADV   # Represents an Adverb\n",
    "    }\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "928d5209-ae26-47c9-9664-674ec21106d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Halla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Halla\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daef6e50-cabb-4c32-9a9b-5889a5e58ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_tokens(tokens):\n",
    "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "# Apply to each column\n",
    "for col in ['Description_cleaned', 'Patient_cleaned', 'Doctor_cleaned']:\n",
    "    df[col] = df[col].apply(lemmatize_tokens)\n",
    "\n",
    "df[['Description_cleaned', 'Patient_cleaned', 'Doctor_cleaned']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da3b3e8-f249-4be4-bbce-45962934e643",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2dfea6-4bfa-40f1-b2bb-5863450d324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f7b772-b4c0-45dc-9963-5c280cdfbbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Create embeddings for the combined text\n",
    "df['combined_text'] = df['Description_cleaned'].apply(lambda x: ' '.join(x)) + ' ' + \\\n",
    "                      df['Patient_cleaned'].apply(lambda x: ' '.join(x)) + ' ' + \\\n",
    "                      df['Doctor_cleaned'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = model.encode(df['combined_text'], show_progress_bar=True)\n",
    "\n",
    "# embeddings is a NumPy array you can use for clustering, similarity, or ML\n",
    "embeddings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed9fd87-d118-42a8-bded-e0653cd5fe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Combine relevant columns into one text field\n",
    "df['combined_text'] = df['Description_cleaned'].apply(lambda x: ' '.join(x)) + ' ' + \\\n",
    "                      df['Patient_cleaned'].apply(lambda x: ' '.join(x)) + ' ' + \\\n",
    "                      df['Doctor_cleaned'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Create TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "     max_features=1000,   # instead of 5000\n",
    "    stop_words='english',\n",
    "    ngram_range=(1,2)\n",
    ")\n",
    "\n",
    "# Fit and transform\n",
    "X_tfidf = tfidf.fit_transform(df['combined_text'])\n",
    "\n",
    "print(X_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a33d1-3f8f-4e0a-b8e8-9a5bb317ea22",
   "metadata": {
    "id": "008a33d1-3f8f-4e0a-b8e8-9a5bb317ea22"
   },
   "source": [
    "**Text Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96de91a-cf0f-4dc3-9dc3-7c8c9a7c2daf",
   "metadata": {
    "id": "f96de91a-cf0f-4dc3-9dc3-7c8c9a7c2daf"
   },
   "source": [
    "Finally, we normalize the text by joining the processed tokens back into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e892765-2534-4e4c-92a2-10fc7fe75c63",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4e892765-2534-4e4c-92a2-10fc7fe75c63",
    "outputId": "7946d807-935c-42cf-9e9e-4c240598fa01"
   },
   "outputs": [],
   "source": [
    "# Convert token lists to cleaned strings\n",
    "for col in ['Description_cleaned', 'Patient_cleaned', 'Doctor_cleaned']:\n",
    "    df[col.replace('_tokens', '_cleaned')] = df[col].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Display the first few rows\n",
    "df[['Description_cleaned', 'Patient_cleaned', 'Doctor_cleaned']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e896532-f251-4271-b203-b1fa3ef9f485",
   "metadata": {
    "id": "5e896532-f251-4271-b203-b1fa3ef9f485"
   },
   "outputs": [],
   "source": [
    "### **Exploratory Data Analysis (EDA)**\n",
    "# Word Frequency Distribution for Patient messages\n",
    "all_patient_words = [word for tokens in df['Patient_cleaned'] for word in tokens]\n",
    "freq_dist_patient = FreqDist(all_patient_words)\n",
    "most_common_patient = freq_dist_patient.most_common(20)\n",
    "# Plotting the most common words\n",
    "words, counts = zip(*most_common_patient)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(words, counts)\n",
    "plt.title('Most Common Words in Patient Messages')\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc146e0-bbf1-4c23-8f4a-5a20f80ac6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31e8ea8-0140-4dc7-8a0c-36553b767516",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "id": "d31e8ea8-0140-4dc7-8a0c-36553b767516",
    "outputId": "4ee18857-43c9-4797-b480-49010fb36593"
   },
   "outputs": [],
   "source": [
    "# Word Frequency Distribution for Doctor messages\n",
    "all_doctor_words = [word for tokens in df['Doctor_cleaned'] for word in tokens]\n",
    "freq_dist_doctor = FreqDist(all_doctor_words)\n",
    "most_common_doctor = freq_dist_doctor.most_common(20)\n",
    "# Plotting the most common words\n",
    "words, counts = zip(*most_common_doctor)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(words, counts)\n",
    "plt.title('Most Common Words in Doctor Messages')\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba95b634-90c1-4dbe-92c5-2c4b16178b59",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "ba95b634-90c1-4dbe-92c5-2c4b16178b59",
    "outputId": "4e00c1c9-35c0-43d9-c162-861b19a67a3e"
   },
   "outputs": [],
   "source": [
    "\n",
    "### **Visualization of Message Lengths**\n",
    "# Calculate message lengths\n",
    "df['Patient_msg_length'] = df['Patient_cleaned'].apply(len)\n",
    "df['Doctor_msg_length'] = df['Doctor_cleaned'].apply(len)\n",
    "\n",
    "# Plotting the message lengths\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(df['Patient_msg_length'], bins=30, alpha=0.5, label='Patient Messages')\n",
    "plt.hist(df['Doctor_msg_length'], bins=30, alpha=0.5, label='Doctor Messages')\n",
    "plt.title('Distribution of Message Lengths')\n",
    "plt.xlabel('Message Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NHFQmuJekM7m",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NHFQmuJekM7m",
    "outputId": "671593a6-a77f-4878-eae0-1ce37ee64e12"
   },
   "outputs": [],
   "source": [
    "# Create new columns for text length in words\n",
    "for col in ['Description_cleaned', 'Patient_cleaned', 'Doctor_cleaned']:\n",
    "    df[col + '_length'] = df[col].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Plot word count distribution for each text column\n",
    "for col in ['Description_cleaned', 'Patient_cleaned', 'Doctor_cleaned']:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.histplot(df[col + '_length'], bins=30, kde=True, color='teal')\n",
    "    plt.title(f\"Word Count Distribution in {col}\")\n",
    "    plt.xlabel(\"Word Count\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fstyKC6vWAj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 631
    },
    "id": "6fstyKC6vWAj",
    "outputId": "bd27b376-0a81-42d9-c71a-6a9687199357"
   },
   "outputs": [],
   "source": [
    "# ploting common pair of words in patient and doctor messages\n",
    "from nltk import bigrams\n",
    "from collections import Counter\n",
    "patient_bigrams = [bigram for tokens in df['Patient_cleaned'] for bigram in bigrams(tokens)]\n",
    "doctor_bigrams = [bigram for tokens in df['Doctor_cleaned'] for bigram in bigrams(tokens)]\n",
    "patient_bigram_counts = Counter(patient_bigrams).most_common(20)\n",
    "doctor_bigram_counts = Counter(doctor_bigrams).most_common(20)\n",
    "# Plotting Patient Bigrams\n",
    "patient_bigrams_words, patient_bigrams_counts = zip(*patient_bigram_counts)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar([' '.join(bigram) for bigram in patient_bigrams_words], patient_bigrams_counts)\n",
    "plt.title('Most Common Bigrams in Patient Messages')\n",
    "plt.xlabel('Bigrams')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wLJHyM0QxUJb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wLJHyM0QxUJb",
    "outputId": "20c2067d-2068-4401-d083-22fdea86904d"
   },
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8007a543-855d-4737-acd0-54c575a72683",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df['Patient_cleaned'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HLfnPIvJwkv7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "HLfnPIvJwkv7",
    "outputId": "c4299040-9307-4013-f3be-10c6ac88530b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ploting wordcloud for doctor and patient messages\n",
    "from wordcloud import WordCloud\n",
    "# Generate wordcloud for Patient messages\n",
    "patient_text = ' '.join(df['Patient_cleaned'])\n",
    "patient_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(patient_text)\n",
    "# Plotting the wordcloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(patient_wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud for Patient Messages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee09e031-d262-4b15-9d6c-b7a8413a1287",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfb2cf6-391d-4009-889d-76f404236ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  FEATURE EXTRACTION using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df['combined_text'])\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3434d983-4de1-4f56-83b1-15fa38014fed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V5E1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
