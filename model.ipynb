{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27776042-5cdb-47ec-877f-cedd22154ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.2-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\user\\anaconda3\\envs\\felix\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Using cached scipy-1.15.3-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\anaconda3\\envs\\felix\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.7.2-cp310-cp310-win_amd64.whl (8.9 MB)\n",
      "Using cached scipy-1.15.3-cp310-cp310-win_amd64.whl (41.3 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   ---------------------------------------- 3/3 [scikit-learn]\n",
      "\n",
      "Successfully installed scikit-learn-1.7.2 scipy-1.15.3 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0804c7b-f5e4-444c-8a1c-4f3b17b70659",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib  # to save the model later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b64995b-755d-4a5f-9342-22a0c12b3908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_model = pd.read_csv(\"my_data.csv\")\n",
    "# df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65046708-4097-4900-8f06-34742611f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f33dc4cc-e2d5-4b51-88d5-093f5d361813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming df_model has \"symptoms_text\" and \"diseases\" columns\n",
    "# X = df_model[\"symptoms_text\"]\n",
    "# y = df_model[\"diseases\"]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42, stratify=y\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46fe5f03-6ce3-403c-a379-f414b826868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(\n",
    "#     max_features=3000,      # limits features for speed\n",
    "#     ngram_range=(1, 2),     # captures phrases like \"chest pain\"\n",
    "#     stop_words=\"english\"    # remove common words\n",
    "# )\n",
    "\n",
    "# X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "# X_test_tfidf = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcebf2e6-e9b3-4c80-b51f-a115a2aca9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LogisticRegression(max_iter=1000)\n",
    "# model.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "331c3925-823d-4928-a940-a36c25c14df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_test_tfidf)\n",
    "# print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13b36404-777f-4620-bb8c-71323d110a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Train accuracy\n",
    "# y_train_pred = model.predict(X_train_tfidf)\n",
    "# train_acc = accuracy_score(y_train, y_train_pred)\n",
    "# print(f\"Training Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "# # Test accuracy\n",
    "# y_test_pred = model.predict(X_test_tfidf)\n",
    "# test_acc = accuracy_score(y_test, y_test_pred)\n",
    "# print(f\"Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e177a9a-cda8-4731-aff4-6c1b05a34ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_disease(symptoms_text):\n",
    "#     text_tfidf = vectorizer.transform([symptoms_text])\n",
    "#     prediction = model.predict(text_tfidf)[0]\n",
    "#     return prediction\n",
    "\n",
    "# # Example:\n",
    "# user_input = \" anxiety and nervousness, shortness of breath,depression ,insomnia\"\n",
    "# print(\"Predicted disease:\", predict_disease(user_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "113f81db-d8d9-496f-b8d3-abad9089cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c06247b7-f841-420d-82b5-a63a4369d50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X = df_model['symptoms_text']\n",
    "# y = df_model['diseases']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42, stratify=y\n",
    "# )\n",
    "\n",
    "# # -------------------------------\n",
    "# # 4Ô∏è‚É£ TF-IDF vectorizer (fit only on train)\n",
    "# # -------------------------------\n",
    "# vectorizer = TfidfVectorizer(max_features=3000, ngram_range=(1,2), stop_words='english')\n",
    "# X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# # -------------------------------\n",
    "# # 5Ô∏è‚É£ Define chatbot function\n",
    "# # -------------------------------\n",
    "# # Rule-based greetings and fallbacks\n",
    "# greetings = [\"hello\", \"hi\", \"hey\", \"good morning\", \"good evening\"]\n",
    "# greeting_responses = [\n",
    "#     \"Hello! How can I help you with your symptoms today?\", \n",
    "#     \"Hi there! Tell me your symptoms so I can assist.\",\n",
    "#     \"Hey! What symptoms are you experiencing?\"\n",
    "# ]\n",
    "\n",
    "# fallback_responses = [\n",
    "#     \"I'm here to help with medical symptoms and possible diseases.\",\n",
    "#     \"Please tell me your symptoms so I can assist you.\"\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c52d487b-a5fb-4a09-8fec-8dad311c9993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Main chatbot function\n",
    "# def medical_chatbot(user_input):\n",
    "#     user_input_lower = user_input.lower()\n",
    "    \n",
    "#     # 1. Greetings\n",
    "#     if any(word in user_input_lower for word in greetings):\n",
    "#         return random.choice(greeting_responses)\n",
    "    \n",
    "#     # 2. Non-medical queries \n",
    "#     symptom_keywords = [\"pain\", \"fever\", \"cough\", \"dizzy\", \"headache\", \"shortness\", \"nausea\"]\n",
    "#     if not any(word in user_input_lower for word in symptom_keywords):\n",
    "#         return random.choice(fallback_responses)\n",
    "    \n",
    "#     # 3. TF-IDF retrieval\n",
    "#     input_vec = vectorizer.transform([user_input])\n",
    "#     similarities = cosine_similarity(input_vec, X_train_tfidf).flatten()\n",
    "#     idx = similarities.argmax()\n",
    "    \n",
    "#     return f\"Based on your symptoms, you might have: {y_train.iloc[idx]}\"\n",
    "\n",
    "# #Evaluate chatbot performan\n",
    "# y_pred = [medical_chatbot(text) for text in X_test]\n",
    "\n",
    "# # Remove \"Based on your symptoms, you might have: \" prefix to match labels\n",
    "# y_pred_clean = [pred.replace(\"Based on your symptoms, you might have: \", \"\") for pred in y_pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e84a2fd1-044e-4581-8aec-29ff374d838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# y_pred_clean = [pred.replace(\"Based on your symptoms, you might have: \", \"\") for pred in y_pred]\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred_clean)\n",
    "# print(f\"Test Accuracy: {accuracy:.4f}\\n\")\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(y_test, y_pred_clean))\n",
    "      \n",
    "# # Optional: interactive chat loop\n",
    "# print(\"\\nMedical Chatbot: type 'exit' to quit\")\n",
    "# while True:\n",
    "#     user_input = input(\"You: \")\n",
    "#     if user_input.lower() == \"exit\":\n",
    "#         print(\"Chatbot: Goodbye!\")\n",
    "#         break\n",
    "#     response = medical_chatbot(user_input)\n",
    "#     print(\"Chatbot:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e030a1e-6a77-4783-800d-1387a40bb305",
   "metadata": {},
   "source": [
    "## RANDOM FOREST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48cd0e7b-820e-48b1-981f-d14bef0289a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "# import random\n",
    "\n",
    "# # ------------------------------------------\n",
    "# # 1. Load data\n",
    "# # ------------------------------------------\n",
    "# # df_model has: 'symptoms_text' and 'diseases'\n",
    "# df = df_model.copy()\n",
    "\n",
    "# # ------------------------------------------\n",
    "# # 2. Train-test split\n",
    "# # ------------------------------------------\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     df[\"symptoms_text\"],\n",
    "#     df[\"diseases\"],\n",
    "#     test_size=0.2,\n",
    "#     random_state=42,\n",
    "#     stratify=df[\"diseases\"]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35a8c1ed-af67-4491-9f14-34832c737a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------------------------------------\n",
    "# # 3. TF-IDF vectorization\n",
    "# # ------------------------------------------\n",
    "# vectorizer = TfidfVectorizer(max_features=3000, ngram_range=(1,2), stop_words=\"english\")\n",
    "# X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "# X_test_tfidf  = vectorizer.transform(X_test)\n",
    "\n",
    "# # 4. Train Random Forest\n",
    "\n",
    "# rf_model = RandomForestClassifier(\n",
    "#     n_estimators=300,\n",
    "#     max_depth=20,\n",
    "#     random_state=42,\n",
    "#     class_weight=\"balanced\",\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# rf_model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c0d77c9-682a-4e30-a3ef-ef2ceae934eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5. Evaluate performance\n",
    "# # ------------------------------------------\n",
    "# y_train_pred = rf_model.predict(X_train_tfidf)\n",
    "# y_test_pred  = rf_model.predict(X_test_tfidf)\n",
    "\n",
    "# print(f\"‚úÖ Training Accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "# print(f\"‚úÖ Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\\n\")\n",
    "# print(\"Classification Report (Test):\")\n",
    "# print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea25987d-53c2-4e14-85c3-1ea1a5b991cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# X = df['symptoms_text']\n",
    "# y = df['diseases']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# # -----------------------------\n",
    "# # 3Ô∏è‚É£ TF-IDF Vectorization (optimized)\n",
    "# # -----------------------------\n",
    "# vectorizer = TfidfVectorizer(\n",
    "#     max_features=5000,\n",
    "#     ngram_range=(1,3),\n",
    "#     stop_words='english',\n",
    "#     sublinear_tf=True\n",
    "# )\n",
    "# X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "# X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# # -----------------------------\n",
    "# # 4Ô∏è‚É£ Random Forest Model (tuned)\n",
    "# # -----------------------------\n",
    "# rf_model = RandomForestClassifier(\n",
    "#     n_estimators=300,\n",
    "#     max_depth=15,\n",
    "#     min_samples_split=5,\n",
    "#     min_samples_leaf=3,\n",
    "#     class_weight='balanced',\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# # -----------------------------\n",
    "# # 5Ô∏è‚É£ Cross-validation (5-fold)\n",
    "# # -----------------------------\n",
    "# cv_scores = cross_val_score(rf_model, X_train_tfidf, y_train, cv=5, scoring='accuracy')\n",
    "# print(f\"Average CV Accuracy: {cv_scores.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4d10e36-c5d0-46a3-bd23-dba2bfb30e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----------------------------\n",
    "# # 6Ô∏è‚É£ Train final model\n",
    "# # -----------------------------\n",
    "# rf_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# # -----------------------------\n",
    "# # 7Ô∏è‚É£ Evaluate performance\n",
    "# # -----------------------------\n",
    "# y_pred_train = rf_model.predict(X_train_tfidf)\n",
    "# y_pred_test = rf_model.predict(X_test_tfidf)\n",
    "\n",
    "# train_acc = accuracy_score(y_train, y_pred_train)\n",
    "# test_acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "# print(f\"\\n‚úÖ Training Accuracy: {train_acc:.4f}\")\n",
    "# print(f\"‚úÖ Test Accuracy: {test_acc:.4f}\")\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9a1245b-d1c9-43c6-838f-22362c9fda5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7f5835e-3858-43f5-981a-7c8b2b8d1e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0210b9e7-a98e-44d4-a5e8-1965102bd98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Load data\n",
    "\n",
    "df = pd.read_csv(\"my_data.csv\")  # columns: symptoms_text, diseases\n",
    "\n",
    "X = df[\"symptoms_text\"].astype(str)\n",
    "y = df[\"diseases\"].astype(str)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# -------------------------------\n",
    "# 2Ô∏è‚É£ Train-test split\n",
    "# -------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 3Ô∏è‚É£ Tokenization & Padding\n",
    "MAX_WORDS = 5000\n",
    "MAX_LEN = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN, padding=\"post\", truncating=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5acb7a53-b6be-4f6d-8a19-d83bfbb2b32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2287/2287 [==============================] - 390s 168ms/step - loss: 1.5715 - accuracy: 0.5300 - val_loss: 0.5239 - val_accuracy: 0.8039\n",
      "Epoch 2/10\n",
      "2287/2287 [==============================] - 366s 160ms/step - loss: 0.5881 - accuracy: 0.7963 - val_loss: 0.3841 - val_accuracy: 0.8523\n",
      "Epoch 3/10\n",
      "2287/2287 [==============================] - 369s 161ms/step - loss: 0.4701 - accuracy: 0.8314 - val_loss: 0.3320 - val_accuracy: 0.8648\n",
      "Epoch 4/10\n",
      "2287/2287 [==============================] - 381s 166ms/step - loss: 0.4120 - accuracy: 0.8458 - val_loss: 0.3087 - val_accuracy: 0.8701\n",
      "Epoch 5/10\n",
      "2287/2287 [==============================] - 389s 170ms/step - loss: 0.3816 - accuracy: 0.8529 - val_loss: 0.2943 - val_accuracy: 0.8739\n",
      "Epoch 6/10\n",
      "2287/2287 [==============================] - 411s 180ms/step - loss: 0.3576 - accuracy: 0.8594 - val_loss: 0.2911 - val_accuracy: 0.8717\n",
      "Epoch 7/10\n",
      "2287/2287 [==============================] - 409s 179ms/step - loss: 0.3431 - accuracy: 0.8620 - val_loss: 0.2737 - val_accuracy: 0.8758\n",
      "Epoch 8/10\n",
      "2287/2287 [==============================] - 404s 177ms/step - loss: 0.3267 - accuracy: 0.8659 - val_loss: 0.2694 - val_accuracy: 0.8761\n",
      "Epoch 9/10\n",
      "2287/2287 [==============================] - 397s 174ms/step - loss: 0.3194 - accuracy: 0.8686 - val_loss: 0.2690 - val_accuracy: 0.8751\n",
      "Epoch 10/10\n",
      "2287/2287 [==============================] - 389s 170ms/step - loss: 0.3088 - accuracy: 0.8691 - val_loss: 0.2629 - val_accuracy: 0.8786\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 4Ô∏è‚É£ Neural Network (Lightweight)\n",
    "# -------------------------------\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=MAX_WORDS, output_dim=128, input_length=MAX_LEN),\n",
    "    Bidirectional(LSTM(64, dropout=0.3, recurrent_dropout=0.2, return_sequences=False)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(len(np.unique(y_encoded)), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# -------------------------------\n",
    "# 5Ô∏è‚É£ Train model\n",
    "# -------------------------------\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_pad, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "600dd5df-05be-4be8-aac9-602bee4a6725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training Accuracy: 0.8854\n",
      "‚úÖ Test Accuracy: 0.8805\n",
      "\n",
      "Classification Report:\n",
      "715/715 [==============================] - 14s 19ms/step\n",
      "                                             precision    recall  f1-score   support\n",
      "\n",
      "                          actinic_keratosis       0.96      0.68      0.79       182\n",
      "                        acute_bronchiolitis       0.94      0.92      0.93       241\n",
      "                           acute_bronchitis       0.79      0.76      0.77       243\n",
      "                         acute_bronchospasm       0.72      0.74      0.73       181\n",
      "                        acute_kidney_injury       0.96      0.98      0.97       182\n",
      "                         acute_pancreatitis       0.84      0.97      0.90       241\n",
      "                            acute_sinusitis       0.79      0.95      0.86       181\n",
      "                      acute_stress_reaction       0.93      0.92      0.93       182\n",
      "                                    allergy       0.97      0.98      0.97       181\n",
      "                                     angina       0.96      0.96      0.96       181\n",
      "                                    anxiety       0.98      0.91      0.94       240\n",
      "                               appendicitis       0.83      0.88      0.85       181\n",
      "                       arthritis_of_the_hip       0.96      0.98      0.97       242\n",
      "                                     asthma       0.77      0.76      0.77       181\n",
      "          benign_prostatic_hyperplasia_bph_       1.00      1.00      1.00       241\n",
      "                                blepharitis       0.76      0.95      0.84       181\n",
      "                          brachial_neuritis       0.96      0.88      0.92       181\n",
      "                                   bursitis       1.00      0.99      0.99       242\n",
      "                     carpal_tunnel_syndrome       0.96      0.94      0.95       179\n",
      "                              cholecystitis       1.00      0.78      0.88       241\n",
      "                          chronic_back_pain       1.00      0.98      0.99       180\n",
      "                       chronic_constipation       0.99      0.85      0.91       183\n",
      "chronic_obstructive_pulmonary_disease_copd_       0.55      0.88      0.68       181\n",
      "                                common_cold       0.85      0.93      0.89       181\n",
      "             complex_regional_pain_syndrome       0.90      0.93      0.92       244\n",
      "                                 concussion       0.99      0.97      0.98       238\n",
      "                             conjunctivitis       0.97      0.91      0.94       182\n",
      "              conjunctivitis_due_to_allergy       0.91      0.94      0.92       243\n",
      "                         contact_dermatitis       0.94      0.75      0.83       182\n",
      "                           cornea_infection       0.98      0.79      0.87       181\n",
      "                                      croup       0.90      0.86      0.88       181\n",
      "                                   cystitis       0.96      0.68      0.80       244\n",
      "                  degenerative_disc_disease       0.65      0.86      0.74       182\n",
      "                              dental_caries       0.99      1.00      0.99       237\n",
      "                                 depression       0.92      0.71      0.80       182\n",
      "                   developmental_disability       0.99      0.96      0.97       182\n",
      "                                diaper_rash       1.00      0.97      0.99       179\n",
      "                             diverticulitis       0.88      0.83      0.86       243\n",
      "                              drug_reaction       1.00      0.97      0.99       182\n",
      "                   dry_eye_of_unknown_cause       0.82      0.88      0.85       172\n",
      "                            ear_drum_damage       0.94      0.97      0.96       181\n",
      "                                     eczema       0.71      0.87      0.78       241\n",
      "                                esophagitis       0.92      0.95      0.94       243\n",
      "  eustachian_tube_dysfunction_ear_disorder_       0.97      0.96      0.96       182\n",
      "                        fracture_of_the_rib       0.99      0.98      0.99       176\n",
      "               fungal_infection_of_the_hair       0.81      0.76      0.78       242\n",
      "                                  gallstone       0.82      0.90      0.86       181\n",
      "                gastrointestinal_hemorrhage       0.95      0.96      0.95       243\n",
      "                                       gout       0.97      0.97      0.97       242\n",
      "                                gum_disease       0.99      0.98      0.99       179\n",
      "                               heart_attack       0.97      0.91      0.94       181\n",
      "                              heart_failure       0.89      0.97      0.93       181\n",
      "                                hemorrhoids       0.94      0.88      0.91       182\n",
      "                             herniated_disk       0.73      0.92      0.82       182\n",
      "                              hiatal_hernia       0.99      0.91      0.95       181\n",
      "                     hyperemesis_gravidarum       0.89      0.96      0.92       182\n",
      "                 hypertensive_heart_disease       0.96      0.98      0.97       180\n",
      "                               hypoglycemia       0.99      0.98      0.98       243\n",
      "          idiopathic_excessive_menstruation       0.85      0.96      0.90       181\n",
      "       idiopathic_irregular_menstrual_cycle       0.91      0.87      0.89       182\n",
      "            idiopathic_painful_menstruation       0.92      0.85      0.88       181\n",
      "                 infectious_gastroenteritis       0.89      0.55      0.68       242\n",
      "                          injury_to_the_arm       0.97      0.95      0.96       242\n",
      "                          injury_to_the_leg       0.97      0.99      0.98       241\n",
      "                        injury_to_the_trunk       0.98      0.97      0.98       181\n",
      "                     ischemic_heart_disease       0.99      0.98      0.99       177\n",
      "                               kidney_stone       0.66      0.69      0.68       181\n",
      "                              liver_disease       0.99      0.95      0.97       242\n",
      "                       macular_degeneration       0.92      0.85      0.89       182\n",
      "                            marijuana_abuse       0.86      0.71      0.78       242\n",
      "                         multiple_sclerosis       0.96      0.96      0.96       182\n",
      "                                   neurosis       0.96      0.92      0.94       180\n",
      "              noninfectious_gastroenteritis       0.62      0.90      0.73       241\n",
      "                              nose_disorder       0.98      0.86      0.91       244\n",
      "               obstructive_sleep_apnea_osa_       1.00      1.00      1.00       239\n",
      "                             osteoarthritis       0.98      0.96      0.97       179\n",
      "              otitis_externa_swimmer_s_ear_       0.94      0.94      0.94       181\n",
      "                               otitis_media       0.98      0.87      0.92       182\n",
      "                    pain_after_an_operation       0.90      0.93      0.92       182\n",
      "                             panic_disorder       0.88      0.97      0.92       182\n",
      "                pelvic_inflammatory_disease       0.88      0.89      0.88       180\n",
      "                  peripheral_nerve_disorder       0.96      0.90      0.93       243\n",
      "                       personality_disorder       0.52      0.77      0.62       182\n",
      "                                  pneumonia       0.98      0.66      0.79       242\n",
      "                   problem_during_pregnancy       0.97      0.88      0.92       183\n",
      "                                  psoriasis       0.82      0.79      0.80       182\n",
      "                         psychotic_disorder       0.68      0.48      0.56       180\n",
      "                         pulmonary_embolism       0.98      0.96      0.97       176\n",
      "                             pyelonephritis       0.67      0.62      0.64       181\n",
      "                    pyogenic_skin_infection       1.00      0.97      0.99       182\n",
      "                            rectal_disorder       0.86      0.97      0.91       180\n",
      "                              schizophrenia       0.58      0.77      0.66       178\n",
      "              seasonal_allergies_hay_fever_       0.99      0.91      0.95       182\n",
      "                             sebaceous_cyst       0.94      0.96      0.95       183\n",
      "                      seborrheic_dermatitis       0.98      0.89      0.93       176\n",
      "                       seborrheic_keratosis       0.70      0.24      0.36       174\n",
      "                                     sepsis       0.94      0.97      0.95       182\n",
      "                         sickle_cell_crisis       0.98      0.95      0.96       183\n",
      "                          sinus_bradycardia       0.94      0.97      0.96       182\n",
      "                 skin_pigmentation_disorder       0.48      0.40      0.44       182\n",
      "                                 skin_polyp       0.38      0.85      0.53       179\n",
      "               smoking_or_tobacco_addiction       1.00      0.99      0.99       177\n",
      "                            spinal_stenosis       0.92      0.74      0.82       241\n",
      "                                spondylosis       0.90      0.76      0.82       243\n",
      "                       spontaneous_abortion       0.83      0.88      0.85       242\n",
      "                           sprain_or_strain       0.87      0.98      0.92       242\n",
      "                               strep_throat       0.98      0.92      0.95       242\n",
      "                                       stye       0.98      0.99      0.99       182\n",
      "         temporary_or_benign_blood_in_urine       0.70      0.97      0.81       179\n",
      "                       threatened_pregnancy       0.77      0.93      0.84       181\n",
      "                    urinary_tract_infection       0.77      0.82      0.79       182\n",
      "                               vaginal_cyst       0.91      0.75      0.82       243\n",
      "                                  vaginitis       0.98      0.96      0.97       182\n",
      "                                 vulvodynia       0.92      0.91      0.91       244\n",
      "\n",
      "                                   accuracy                           0.88     22863\n",
      "                                  macro avg       0.89      0.88      0.88     22863\n",
      "                               weighted avg       0.89      0.88      0.88     22863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance\n",
    "train_loss, train_acc = model.evaluate(X_train_pad, y_train, verbose=0)\n",
    "test_loss, test_acc = model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "\n",
    "print(f\"‚úÖ Training Accuracy: {train_acc:.4f}\")\n",
    "print(f\"‚úÖ Test Accuracy: {test_acc:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "y_pred = np.argmax(model.predict(X_test_pad), axis=1)\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dda60e93-1214-47bc-84b4-3298e7b38aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model, tokenizer, and label encoder saved successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\felix\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save model and tokenizer\n",
    "model.save(\"medical_nn_model.h5\")\n",
    "joblib.dump(tokenizer, \"tokenizer.pkl\")\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
    "print(\"\\n Model, tokenizer, and label encoder saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "10dde41b-ff6b-46ae-9882-d803aa1e73d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'saving_api' from 'tensorflow.keras.saving' (C:\\Users\\USER\\anaconda3\\envs\\felix\\lib\\site-packages\\keras\\api\\_v2\\keras\\saving\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m saving_api\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m saving_api\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedical_nn_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'saving_api' from 'tensorflow.keras.saving' (C:\\Users\\USER\\anaconda3\\envs\\felix\\lib\\site-packages\\keras\\api\\_v2\\keras\\saving\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.saving import saving_api\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = saving_api.load_model('medical_nn_model.h5', compile=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c1d5232-5b6e-456e-a6fc-554d3a6e11e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def medical_chatbot(user_input):\n",
    "#     import random\n",
    "#     greetings = [\"hello\", \"hi\", \"hey\", \"good morning\", \"good evening\"]\n",
    "#     responses = [\"Hello! How can I assist you today?\", \"Hi there! What symptoms are you experiencing?\"]\n",
    "    \n",
    "#     if any(g in user_input.lower() for g in greetings):\n",
    "#         return random.choice(responses)\n",
    "    \n",
    "#     seq = tokenizer.texts_to_sequences([user_input])\n",
    "#     pad = pad_sequences(seq, maxlen=MAX_LEN, padding='post')\n",
    "#     pred = model.predict(pad)\n",
    "#     disease = label_encoder.inverse_transform([np.argmax(pred)])[0]\n",
    "#     return f\"Based on your symptoms, you might have: {disease}\"\n",
    "\n",
    "# # -------------------------------\n",
    "# # üí¨ Try the chatbot\n",
    "# print(\"\\nChatbot ready! Type 'exit' to stop.\")\n",
    "# while True:\n",
    "#     user_input = input(\"You: \")\n",
    "#     if user_input.lower() == \"exit\":\n",
    "#         print(\"Chatbot: Goodbye!\")\n",
    "#         break\n",
    "#     print(\"Chatbot:\", medical_chatbot(user_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59580e20-5b1e-46b5-ad58-3071a4111ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 6. Add chatbot functionality\n",
    "# # ------------------------------------------\n",
    "# greetings = [\"hi\", \"hello\", \"hey\", \"good morning\", \"good evening\"]\n",
    "# greeting_responses = [\"Hello! How can I help you today?\", \"Hi there!\", \"Hey! Tell me your symptoms.\"]\n",
    "\n",
    "# def medical_chatbot(user_input):\n",
    "#     user_input_lower = user_input.lower()\n",
    "\n",
    "#     # Greeting handler\n",
    "#     if any(greet in user_input_lower for greet in greetings):\n",
    "#         return random.choice(greeting_responses)\n",
    "\n",
    "#     # Predict disease from input\n",
    "#     input_vec = vectorizer.transform([user_input])\n",
    "#     prediction = rf_model.predict(input_vec)[0]\n",
    "#     return f\"Based on your symptoms, you might have: {prediction}\"\n",
    "\n",
    "# # ------------------------------------------\n",
    "# # 7. Interactive chat\n",
    "# # ------------------------------------------\n",
    "# print(\"\\n Medical Chatbot: Type 'exit' to quit.\")\n",
    "# while True:\n",
    "#     user_input = input(\"You: \")\n",
    "#     if user_input.lower() == \"exit\":\n",
    "#         print(\"Chatbot: Goodbye! Take care ‚ù§Ô∏è\")\n",
    "#         break\n",
    "#     print(\"Chatbot:\", medical_chatbot(user_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e58644e-b567-4423-b168-5045bae03b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aee6b869-acb2-4327-94b7-40cb6ee81a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import pandas as pd\n",
    "\n",
    "# # Save TF-IDF vectorizer\n",
    "# with open(\"tfidf_vectorizer.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(vectorizer, f)\n",
    "\n",
    "# # Save training data\n",
    "# train_data = pd.DataFrame({\n",
    "#     \"symptoms_text\": X_train,   # or df_model['symptoms_text']\n",
    "#     \"diseases\": y_train         # or df_model['diseases']\n",
    "# })\n",
    "# train_data.to_csv(\"train_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7173948-fee7-47b4-9bb2-c51abb100fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import pandas as pd\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# import random\n",
    "\n",
    "# # Load vectorizer and training data\n",
    "# with open(\"tfidf_vectorizer.pkl\", \"rb\") as f:\n",
    "#     vectorizer = pickle.load(f)\n",
    "\n",
    "# train_data = pd.read_csv(\"train_data.csv\")\n",
    "# X_train = train_data['symptoms_text']\n",
    "# y_train = train_data['diseases']\n",
    "\n",
    "# greetings = [\"hello\", \"hi\", \"hey\", \"good morning\", \"good evening\"]\n",
    "# greeting_responses = [\n",
    "#     \"Hello! How can I help you with your symptoms today?\", \n",
    "#     \"Hi there! Tell me your symptoms so I can assist.\",\n",
    "#     \"Hey! What symptoms are you experiencing?\"\n",
    "# ]\n",
    "# fallback_responses = [\n",
    "#     \"I'm here to help with medical symptoms and possible diseases.\",\n",
    "#     \"Please tell me your symptoms so I can assist you.\"\n",
    "# ]\n",
    "\n",
    "# def medical_chatbot(user_input):\n",
    "#     user_input_lower = user_input.lower()\n",
    "#     if any(word in user_input_lower for word in greetings):\n",
    "#         return random.choice(greeting_responses)\n",
    "    \n",
    "#     symptom_keywords = [\"pain\", \"fever\", \"cough\", \"dizzy\", \"headache\", \"shortness\", \"nausea\"]\n",
    "#     if not any(word in user_input_lower for word in symptom_keywords):\n",
    "#         return random.choice(fallback_responses)\n",
    "    \n",
    "#     input_vec = vectorizer.transform([user_input])\n",
    "    # similarities = cosine_similarity(input_vec, vectorizer.transform(X_train)).flatten()\n",
    "    # idx = similarities.argmax()\n",
    "    \n",
    "    # return f\"Based on your symptoms, you might have: {y_train.iloc[idx]}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f9b8a20-413d-458c-8d9b-92a7956d27f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from medical_chatbot import medical_chatbot\n",
    "\n",
    "# while True:\n",
    "#     user_input = input(\"You: \")\n",
    "#     if user_input.lower() == \"exit\":\n",
    "#         print(\"Chatbot: Goodbye!\")\n",
    "#         break\n",
    "#     print(\"Chatbot:\", medical_chatbot(user_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6366182d-7d8c-4c01-b579-a9e94b9a2660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastapi import FastAPI, Request\n",
    "# from fastapi.middleware.cors import CORSMiddleware\n",
    "# import joblib\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# import re\n",
    "\n",
    "# #  Initialize FastAPI \n",
    "# app = FastAPI(title=\"Doc-AI Backend\")\n",
    "\n",
    "# app.add_middleware(\n",
    "#     CORSMiddleware,\n",
    "#     allow_origins=[\"*\"],\n",
    "#     allow_methods=[\"*\"],\n",
    "#     allow_headers=[\"*\"],\n",
    "# )\n",
    "\n",
    "# # Load model, tokenizer, and encoder \n",
    "# print(\" Loading model and preprocessors...\")\n",
    "# model = tf.keras.models.load_model(\"medical_nn_model.h5\")\n",
    "# tokenizer = joblib.load(\"tokenizer.pkl\")\n",
    "# label_encoder = joblib.load(\"label_encoder.pkl\")\n",
    "# print(\"Model, tokenizer, and label encoder loaded successfully!\")\n",
    "\n",
    "# # Greeting and fallback patterns \n",
    "# GREETINGS = [\n",
    "#     \"hi\", \"hello\", \"hey\", \"good morning\", \"good afternoon\", \"good evening\", \"what‚Äôs up\", \"heyy\", \"yo\", \"yoh\", \"how are you\",\"Wassup\",\"Wagwan\"\n",
    "# ]\n",
    "# THANKS = [\n",
    "#     \"thank you\", \"thanks\", \"appreciate\", \"grateful\",\"Okay\",\"Ok\"\n",
    "# ]\n",
    "# BYE = [\n",
    "#     \"bye\", \"goodbye\", \"see you\", \"talk later\",\"later\"\n",
    "# ]\n",
    "\n",
    "# # clean and preprocess text \n",
    "# def clean_text(text):\n",
    "#     text = text.lower().strip()\n",
    "#     text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "#     return text\n",
    "\n",
    "# def preprocess_text(text: str):\n",
    "#     seq = tokenizer.texts_to_sequences([text])\n",
    "#     if not seq or len(seq[0]) == 0:\n",
    "#         return None\n",
    "#     return pad_sequences(seq, maxlen=100)  \n",
    "\n",
    "# # Main prediction route \n",
    "# @app.post(\"/predict\")\n",
    "# async def predict(request: Request):\n",
    "#     data = await request.json()\n",
    "#     user_input = clean_text(data.get(\"text\", \"\").strip())\n",
    "\n",
    "#     if not user_input:\n",
    "#         return {\n",
    "#             \"bot_message\": \"Please describe how you're feeling so I can help.\",\n",
    "#             \"status\": \"error\"\n",
    "    #     }\n",
    "\n",
    "    # # Handle greetings \n",
    "    # if any(greet in user_input for greet in GREETINGS):\n",
    "    #     return {\n",
    "    #         \"bot_message\": (\n",
    "    #             \"üëã Hey there! I‚Äôm **Doc-AI**, your health companion.\\n\"\n",
    "    #             \"Felling a bit off today?Tell me about your symptoms and I'll try to help.\"\n",
    "    #         ),\n",
    "    #         \"status\": \"greeting\"\n",
    "    #     }\n",
    "\n",
    "    # #  Handle gratitude \n",
    "    # if any(thank in user_input for thank in THANKS):\n",
    "    #     return {\n",
    "    #         \"bot_message\": (\n",
    "    #             \"üòä You‚Äôre most welcome! I‚Äôm here to help. \"\n",
    "    #             \"If you have more symptoms, just tell me.\"\n",
    "    #         ),\n",
    "    #         \"status\": \"gratitude\"\n",
    "    #     }\n",
    "\n",
    "    # # === Handle goodbye ===\n",
    "    # if any(bye in user_input for bye in BYE):\n",
    "    #     return {\n",
    "    #         \"bot_message\": (\n",
    "    #             \"üëã Take care of yourself! Remember, if symptoms persist, \"\n",
    "    #             \"please visit a healthcare professional.\"\n",
    "    #         ),\n",
    "    #         \"status\": \"goodbye\"\n",
    "    #     }\n",
    "\n",
    "    # # Predict from symptom description \n",
    "    # X_input = preprocess_text(user_input)\n",
    "    # if X_input is None:\n",
    "    #     return {\n",
    "    #         \"bot_message\": (\n",
    "    #             \"ü§î I couldn‚Äôt detect your condition it might be out of my scope of expertise.\\n\"\n",
    "    #         \"For more information please visit the link below\"\n",
    "                \n",
    "    #         ),\n",
    "    #         \"status\": \"fallback\"\n",
    "    #     }\n",
    "\n",
    "    # probs = model.predict(X_input)[0]\n",
    "    # top_indices = np.argsort(probs)[::-1][:2]\n",
    "    # predictions = [\n",
    "    #     {\n",
    "    #         \"disease\": label_encoder.inverse_transform([i])[0],\n",
    "    #         \"probability\": float(probs[i])\n",
    "    #     }\n",
    "    #     for i in top_indices\n",
    "    # ]\n",
    "\n",
    "    # main_pred = predictions[0]\n",
    "#     alt_pred = predictions[1]\n",
    "#     confidence = main_pred[\"probability\"]\n",
    "#     CONF_THRESHOLD = 0.45\n",
    "\n",
    "#     # === Low confidence fallback ===\n",
    "#     if confidence < CONF_THRESHOLD:\n",
    "#         return {\n",
    "#             \"bot_message\": (\n",
    "#                 \"I‚Äôm not entirely sure what condition this might be. \"\n",
    "#                 \"It could be something mild, but it‚Äôs best to consult a doctor for a precise diagnosis.\"\n",
    "#             ),\n",
    "#             \"status\": \"uncertain\",\n",
    "#             \"confidence\": confidence\n",
    "#         }\n",
    "\n",
    "#     # Conversational response \n",
    "#     main_name = main_pred[\"disease\"]\n",
    "\n",
    "# bot_message = (\n",
    "#         f\"From what you‚Äôve shared, you‚Äôre **most likely** experiencing **{main_name}**. \"\n",
    "#         f\"It might also be **{alt_name}**, depending on how your symptoms progress.\\n\\n\"\n",
    "#         \"Please monitor your symptoms and visit a healthcare provider for medical assistance.\"\n",
    "#     )\n",
    "\n",
    "#     return {\n",
    "#         \"bot_message\": bot_message,\n",
    "#         \"main_prediction\": main_name,\n",
    "#         \"alt_prediction\": alt_name,\n",
    "#         \"status\": \"ok\",\n",
    "#         \"confidence\": confidence\n",
    "#     }\n",
    "\n",
    "# # === Health check route ===\n",
    "# @app.get(\"/\")\n",
    "# def home():\n",
    "#     return {\"message\": \"Doc-AI backend is running smoothly!\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fef4fae6-5683-4f1b-b779-c0bf350a5ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# FOLLOW_UP_QUESTIONS = {\n",
    "#     \"pain\": [\n",
    "#         \"Where exactly do you feel the pain?\",\n",
    "#         \"How long have you had the pain?\",\n",
    "#         \"Is it constant or does it come and go?\"\n",
    "#     ],\n",
    "#     \"cough\": [\n",
    "#         \"Is it a dry cough or are you producing mucus?\",\n",
    "#         \"Have you noticed any fever or shortness of breath?\",\n",
    "#         \"How long have you been coughing?\"\n",
    "#     ],\n",
    "#     \"fever\": [\n",
    "#         \"Do you know how high your temperature has been?\",\n",
    "#         \"Have you experienced chills or sweating?\",\n",
    "#         \"When did the fever start?\"\n",
    "#     ],\n",
    "#     \"fatigue\": [\n",
    "#         \"Have you been sleeping normally?\",\n",
    "#         \"Are you also experiencing dizziness or weakness?\",\n",
    "#         \"Has the fatigue been getting worse over time?\"\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# def get_follow_up(user_input: str):\n",
    "#     \"\"\"Return a relevant clarifying question if a known symptom is found.\"\"\"\n",
    "#     for keyword, questions in FOLLOW_UP_QUESTIONS.items():\n",
    "#         if keyword in user_input:\n",
    "#             return random.choice(questions)\n",
    "#     return random.choice([\n",
    "#         \"Can you describe any other symptoms you‚Äôre feeling?\",\n",
    "#         \"When did these symptoms start?\",\n",
    "#         \"Have you noticed any changes in your appetite or sleep?\",\n",
    "#     ])\n",
    "# from lead_questions import get_follow_up"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:felix]",
   "language": "python",
   "name": "conda-env-felix-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
